{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"updated-traffic-sign-detector-model-train.ipynb","provenance":[{"file_id":"19ycUy5qIZKCO8tKy37f4zkUiHzgKs05I","timestamp":1650232735865}],"machine_shape":"hm","collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### **Installations, version checks, imports and initializations**"],"metadata":{"id":"zodC4ALEoYG7"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1NUxAhxOrnZk","executionInfo":{"status":"ok","timestamp":1650484740125,"user_tz":240,"elapsed":15635,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"31f0e3a7-aaec-454c-d7d9-52c8c6a5803c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["REQUIRED_FILES_DRIVE_PATH = \"/content/drive/MyDrive/DurhamCollege/AIDI/term2/PROJECT-SHARED/AI-ENTERPRISE/required_files\"\n","TRAIN_IMAGES_DRIVE_PATH = \"/content/drive/MyDrive/DurhamCollege/AIDI/term2/PROJECT-SHARED/AI-ENTERPRISE/pascal_xml_annotation/train\"\n","TEST_IMAGES_DRIVE_PATH = \"/content/drive/MyDrive/DurhamCollege/AIDI/term2/PROJECT-SHARED/AI-ENTERPRISE/pascal_xml_annotation/test\""],"metadata":{"id":"f8OWYaSNdHtA","executionInfo":{"status":"ok","timestamp":1650484740126,"user_tz":240,"elapsed":66,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"GnVG7OmvsAOR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650484784867,"user_tz":240,"elapsed":44796,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"898e8ef5-231d-4518-8847-b223d4253652"},"source":["!pip install tensorflow-gpu==2.8.0"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow-gpu==2.8.0\n","  Downloading tensorflow_gpu-2.8.0-cp37-cp37m-manylinux2010_x86_64.whl (497.5 MB)\n","\u001b[K     |████████████████████████████████| 497.5 MB 22 kB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.8.0) (0.24.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.8.0) (1.1.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.8.0) (1.14.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.8.0) (3.1.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.8.0) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.8.0) (4.1.1)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.8.0) (13.0.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.8.0) (3.3.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.8.0) (3.17.3)\n","Collecting tf-estimator-nightly==2.8.0.dev2021122109\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 89.0 MB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.8.0) (1.1.0)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.8.0) (2.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.8.0) (2.8.0)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.8.0) (2.8.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.8.0) (1.15.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.8.0) (0.5.3)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.8.0) (0.2.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.8.0) (57.4.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.8.0) (1.44.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.8.0) (1.0.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.8.0) (1.6.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow-gpu==2.8.0) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-gpu==2.8.0) (1.5.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (1.8.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (1.35.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (3.3.6)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (0.4.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2.23.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (1.0.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (0.6.1)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2021.10.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (3.2.0)\n","Installing collected packages: tf-estimator-nightly, tensorflow-gpu\n","Successfully installed tensorflow-gpu-2.8.0 tf-estimator-nightly-2.8.0.dev2021122109\n"]}]},{"cell_type":"code","source":["!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"],"metadata":{"id":"xuyJ1k8MzIfD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650484833695,"user_tz":240,"elapsed":48841,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"3a7412e6-0a46-4de4-adb7-194d1a3dd505"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following packages will be REMOVED:\n","  libcudnn8-dev\n","The following held packages will be changed:\n","  libcudnn8\n","The following packages will be upgraded:\n","  libcudnn8\n","1 upgraded, 0 newly installed, 1 to remove and 37 not upgraded.\n","Need to get 430 MB of archives.\n","After this operation, 3,139 MB disk space will be freed.\n","Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8 8.1.0.77-1+cuda11.2 [430 MB]\n","Fetched 430 MB in 8s (56.4 MB/s)\n","(Reading database ... 155455 files and directories currently installed.)\n","Removing libcudnn8-dev (8.0.5.39-1+cuda11.1) ...\n","(Reading database ... 155433 files and directories currently installed.)\n","Preparing to unpack .../libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb ...\n","Unpacking libcudnn8 (8.1.0.77-1+cuda11.2) over (8.0.5.39-1+cuda11.1) ...\n","Setting up libcudnn8 (8.1.0.77-1+cuda11.2) ...\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","tf.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"EgQuKr-WYqTS","executionInfo":{"status":"ok","timestamp":1650484836753,"user_tz":240,"elapsed":3071,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"afe86a5f-888e-43d7-9643-a336c4b1963e"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.8.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["### **Clone TF OD API repo from github**"],"metadata":{"id":"92q0UqUKm2aB"}},{"cell_type":"code","metadata":{"id":"kFkdXoEltLY9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650484852486,"user_tz":240,"elapsed":15762,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"c43f2653-64ab-4385-c4c3-05583a9f440c"},"source":["!git clone https://github.com/tensorflow/models.git"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'models'...\n","remote: Enumerating objects: 71984, done.\u001b[K\n","remote: Counting objects: 100% (16/16), done.\u001b[K\n","remote: Compressing objects: 100% (16/16), done.\u001b[K\n","remote: Total 71984 (delta 4), reused 1 (delta 0), pack-reused 71968\u001b[K\n","Receiving objects: 100% (71984/71984), 578.92 MiB | 42.11 MiB/s, done.\n","Resolving deltas: 100% (50919/50919), done.\n"]}]},{"cell_type":"code","metadata":{"id":"aJ4YzpQ4tMlz","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1650484852488,"user_tz":240,"elapsed":50,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"fc543d14-0130-486c-f8eb-1f74830308f0"},"source":["pwd"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"6ZwI0sTdtMsc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650484852489,"user_tz":240,"elapsed":47,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"cfcea193-f6aa-417a-b0fd-c8caaf181f9c"},"source":["cd /content/models/research"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/models/research\n"]}]},{"cell_type":"code","metadata":{"id":"SK5RyNz9tMvZ","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1650484852490,"user_tz":240,"elapsed":42,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"6838fdba-c5b8-4de6-aa3f-eeb496e2a991"},"source":["pwd"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/models/research'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["!wget -O protobuf.zip https://github.com/google/protobuf/releases/download/v3.0.0/protoc-3.0.0-linux-x86_64.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tuPznaO1fDXO","executionInfo":{"status":"ok","timestamp":1650484852491,"user_tz":240,"elapsed":39,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"9289b715-c597-402f-aa47-06e64a892b0c"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-04-20 20:00:51--  https://github.com/google/protobuf/releases/download/v3.0.0/protoc-3.0.0-linux-x86_64.zip\n","Resolving github.com (github.com)... 140.82.113.4\n","Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://github.com/protocolbuffers/protobuf/releases/download/v3.0.0/protoc-3.0.0-linux-x86_64.zip [following]\n","--2022-04-20 20:00:51--  https://github.com/protocolbuffers/protobuf/releases/download/v3.0.0/protoc-3.0.0-linux-x86_64.zip\n","Reusing existing connection to github.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/23357588/c692d808-54ca-11e6-90f6-ef943b0908bf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220420%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220420T200052Z&X-Amz-Expires=300&X-Amz-Signature=4a26d41b718ce6224c8605663f25e3975ab4ed7230626c3d5156b0ab4d48b147&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=23357588&response-content-disposition=attachment%3B%20filename%3Dprotoc-3.0.0-linux-x86_64.zip&response-content-type=application%2Foctet-stream [following]\n","--2022-04-20 20:00:52--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/23357588/c692d808-54ca-11e6-90f6-ef943b0908bf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220420%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220420T200052Z&X-Amz-Expires=300&X-Amz-Signature=4a26d41b718ce6224c8605663f25e3975ab4ed7230626c3d5156b0ab4d48b147&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=23357588&response-content-disposition=attachment%3B%20filename%3Dprotoc-3.0.0-linux-x86_64.zip&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1296281 (1.2M) [application/octet-stream]\n","Saving to: ‘protobuf.zip’\n","\n","protobuf.zip        100%[===================>]   1.24M  --.-KB/s    in 0.05s   \n","\n","2022-04-20 20:00:52 (23.3 MB/s) - ‘protobuf.zip’ saved [1296281/1296281]\n","\n"]}]},{"cell_type":"code","source":["!unzip protobuf.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"60cle5LkfFjb","executionInfo":{"status":"ok","timestamp":1650484852638,"user_tz":240,"elapsed":174,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"3c104e4a-6f59-425a-ed90-469f1a18286d"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  protobuf.zip\n","   creating: include/\n","   creating: include/google/\n","   creating: include/google/protobuf/\n","  inflating: include/google/protobuf/struct.proto  \n","  inflating: include/google/protobuf/type.proto  \n","  inflating: include/google/protobuf/descriptor.proto  \n","  inflating: include/google/protobuf/api.proto  \n","  inflating: include/google/protobuf/empty.proto  \n","   creating: include/google/protobuf/compiler/\n","  inflating: include/google/protobuf/compiler/plugin.proto  \n","  inflating: include/google/protobuf/any.proto  \n","  inflating: include/google/protobuf/field_mask.proto  \n","  inflating: include/google/protobuf/wrappers.proto  \n","  inflating: include/google/protobuf/timestamp.proto  \n","  inflating: include/google/protobuf/duration.proto  \n","  inflating: include/google/protobuf/source_context.proto  \n","   creating: bin/\n","  inflating: bin/protoc              \n","  inflating: readme.txt              \n"]}]},{"cell_type":"code","source":["!./bin/protoc object_detection/protos/*.proto --python_out=."],"metadata":{"id":"9FYWTHZVfJgS","executionInfo":{"status":"ok","timestamp":1650484852640,"user_tz":240,"elapsed":8,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"NozH3MfAtMyR","executionInfo":{"status":"ok","timestamp":1650484852772,"user_tz":240,"elapsed":138,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}}},"source":["!protoc object_detection/protos/*.proto --python_out=."],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"alOqL7ortM1F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650484853595,"user_tz":240,"elapsed":826,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"12fb679b-8c0a-4d0d-b87d-2f3c0c74ce3e"},"source":["!git clone https://github.com/cocodataset/cocoapi.git\n"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'cocoapi'...\n","remote: Enumerating objects: 975, done.\u001b[K\n","remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n","Receiving objects: 100% (975/975), 11.72 MiB | 33.07 MiB/s, done.\n","Resolving deltas: 100% (576/576), done.\n"]}]},{"cell_type":"code","metadata":{"id":"0XRlMiuEtM4R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650484853596,"user_tz":240,"elapsed":13,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"864d93d6-1fad-4687-d562-2697f3b2a2c1"},"source":["cd cocoapi/PythonAPI"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/models/research/cocoapi/PythonAPI\n"]}]},{"cell_type":"code","metadata":{"id":"PZ-xj6MUtM7U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650484858203,"user_tz":240,"elapsed":4613,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"66d86221-7883-4aee-e8f0-320576569e4a"},"source":["!make"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["python setup.py build_ext --inplace\n","running build_ext\n","cythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n","/usr/local/lib/python3.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/models/research/cocoapi/PythonAPI/pycocotools/_mask.pyx\n","  tree = Parsing.p_module(s, pxd, full_module_name)\n","building 'pycocotools._mask' extension\n","creating build\n","creating build/common\n","creating build/temp.linux-x86_64-3.7\n","creating build/temp.linux-x86_64-3.7/pycocotools\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.7/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n","       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n","       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n","                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n","   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n","   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n","                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n","   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n","   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n","                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n","       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n","       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n","                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n","   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n","   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n","                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n","     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n","     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n","                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n","       if(j%2==0) xp=x; else if\u001b[01;35m\u001b[K(\u001b[m\u001b[Kxp<x) { ys=0; ye=h-1; }\n","                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n","creating build/lib.linux-x86_64-3.7\n","creating build/lib.linux-x86_64-3.7/pycocotools\n","x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-dIfpci/python3.7-3.7.13=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/../common/maskApi.o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -o build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so\n","copying build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so -> pycocotools\n","rm -rf build\n"]}]},{"cell_type":"code","metadata":{"id":"A5Qr7ACCtM_b","executionInfo":{"status":"ok","timestamp":1650484858206,"user_tz":240,"elapsed":15,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}}},"source":["cp -r pycocotools /content/models/research"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rLq79dR0uQFt"},"source":["### **Install the Object Detection API**"]},{"cell_type":"code","metadata":{"id":"DM2bgHvLtNFt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650484858421,"user_tz":240,"elapsed":17,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"00e3797f-606a-4004-9c43-564613aee4dd"},"source":["cd .."],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/models/research/cocoapi\n"]}]},{"cell_type":"code","metadata":{"id":"MZouxA5TuWgV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650484858422,"user_tz":240,"elapsed":15,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"b51a76e0-471f-44c9-a191-4bedbd5ab65e"},"source":["cd .. "],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/models/research\n"]}]},{"cell_type":"code","metadata":{"id":"Q635Jl58uWjI","executionInfo":{"status":"ok","timestamp":1650484858424,"user_tz":240,"elapsed":11,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}}},"source":["cp object_detection/packages/tf2/setup.py ."],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZyrPaXSxuWmI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650484893083,"user_tz":240,"elapsed":34668,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"6532b27b-a1f3-4809-a5ff-354f8c1ccbcd"},"source":["!python -m pip install ."],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing /content/models/research\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Collecting avro-python3\n","  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n","Collecting apache-beam\n","  Downloading apache_beam-2.37.0-cp37-cp37m-manylinux2010_x86_64.whl (10.1 MB)\n","\u001b[K     |████████████████████████████████| 10.1 MB 8.0 MB/s \n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.28)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n","Collecting tf-slim\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","\u001b[K     |████████████████████████████████| 352 kB 59.7 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n","Collecting lvis\n","  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n","Collecting tf-models-official>=2.5.1\n","  Downloading tf_models_official-2.8.0-py2.py3-none-any.whl (2.2 MB)\n","\u001b[K     |████████████████████████████████| 2.2 MB 63.7 MB/s \n","\u001b[?25hCollecting tensorflow_io\n","  Downloading tensorflow_io-0.24.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.4 MB)\n","\u001b[K     |████████████████████████████████| 23.4 MB 701 kB/s \n","\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.8.0)\n","Collecting pyyaml<6.0,>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 72.3 MB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 79.2 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n","Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.6)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n","Collecting tensorflow-model-optimization>=0.4.1\n","  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n","\u001b[K     |████████████████████████████████| 237 kB 96.0 MB/s \n","\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 2.8 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow~=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n","\u001b[K     |████████████████████████████████| 90 kB 11.3 MB/s \n","\u001b[?25hCollecting tensorflow-text~=2.8.0\n","  Downloading tensorflow_text-2.8.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[K     |████████████████████████████████| 4.9 MB 90.1 MB/s \n","\u001b[?25hCollecting py-cpuinfo>=3.3.0\n","  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n","\u001b[K     |████████████████████████████████| 99 kB 12.8 MB/s \n","\u001b[?25hCollecting opencv-python-headless\n","  Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n","\u001b[K     |████████████████████████████████| 47.8 MB 116.4 MB/s \n","\u001b[?25hCollecting tensorflow-addons\n","  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 60.1 MB/s \n","\u001b[?25hRequirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n","Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.31.5)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.0)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2022.1)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.10.8)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.0)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.1)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.8)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (13.0.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.24.0)\n","Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.8.0.dev2021122109)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.44.0)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.5.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.8.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n","Collecting cloudpickle<3,>=2.0.0\n","  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n","Collecting fastavro<2,>=0.23.6\n","  Downloading fastavro-1.4.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","\u001b[K     |████████████████████████████████| 2.3 MB 71.5 MB/s \n","\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n","  Downloading dill-0.3.1.1.tar.gz (151 kB)\n","\u001b[K     |████████████████████████████████| 151 kB 77.2 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow<7.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n","Collecting orjson<4.0\n","  Downloading orjson-3.6.8-cp37-cp37m-manylinux_2_24_x86_64.whl (253 kB)\n","\u001b[K     |████████████████████████████████| 253 kB 67.8 MB/s \n","\u001b[?25hCollecting requests<3.0.0dev,>=2.18.0\n","  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.2 MB/s \n","\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n","  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n","\u001b[K     |████████████████████████████████| 508 kB 85.5 MB/s \n","\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Collecting hdfs<3.0.0,>=2.1.0\n","  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n","Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Collecting proto-plus<2,>=1.7.1\n","  Downloading proto_plus-1.20.3-py3-none-any.whl (46 kB)\n","\u001b[K     |████████████████████████████████| 46 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n","Collecting protobuf>=3.12.0\n","  Downloading protobuf-3.20.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n","\u001b[K     |████████████████████████████████| 1.0 MB 83.6 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.12)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.4.2)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n","Collecting portalocker\n","  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.7.0)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.7.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n","Building wheels for collected packages: object-detection, py-cpuinfo, dill, avro-python3, seqeval\n","  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1690985 sha256=283909c656fdad757d493a3d941bebdb5dd485360da7210940a6ff393116cec6\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-k6rvts3v/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n","  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=0e179f596ec798bb52272a76541f4ee2565bbace7e80101323e437e0bebbef81\n","  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n","  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=4f704087e30e297b8d685ac01501133da0bf03b3aa40517201cbb80ddf6e12ab\n","  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n","  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=2dd4a1c15fc3e473c96776b82ea63ef08e7b17b80ead2ce5f335fcdc8555144e\n","  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=1288ee36387380a85c1498b3f9759777500930c96bf9306c04f83d5c6172ffaf\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built object-detection py-cpuinfo dill avro-python3 seqeval\n","Installing collected packages: requests, protobuf, portalocker, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, opencv-python-headless, hdfs, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.17.3\n","    Uninstalling protobuf-3.17.3:\n","      Successfully uninstalled protobuf-3.17.3\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.4\n","    Uninstalling dill-0.3.4:\n","      Successfully uninstalled dill-0.3.4\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: pymongo\n","    Found existing installation: pymongo 4.1.1\n","    Uninstalling pymongo-4.1.1:\n","      Successfully uninstalled pymongo-4.1.1\n","  Attempting uninstall: cloudpickle\n","    Found existing installation: cloudpickle 1.3.0\n","    Uninstalling cloudpickle-1.3.0:\n","      Successfully uninstalled cloudpickle-1.3.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n","gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed apache-beam-2.37.0 avro-python3-1.10.2 cloudpickle-2.0.0 colorama-0.4.4 dill-0.3.1.1 fastavro-1.4.10 hdfs-2.7.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.5.64 orjson-3.6.8 portalocker-2.4.0 proto-plus-1.20.3 protobuf-3.20.0 py-cpuinfo-8.0.0 pymongo-3.12.3 pyyaml-5.4.1 requests-2.27.1 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.16.1 tensorflow-io-0.24.0 tensorflow-model-optimization-0.7.2 tensorflow-text-2.8.1 tf-models-official-2.8.0 tf-slim-1.1.0\n"]}]},{"cell_type":"code","metadata":{"id":"cjlR4lsmuWpE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650484923217,"user_tz":240,"elapsed":30144,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"1315534a-f208-4a1c-b38d-40b585f17bd8"},"source":["# Testing if the env is working so far.\n","!python object_detection/builders/model_builder_tf2_test.py"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Running tests under Python 3.7.13: /usr/bin/python3\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","2022-04-20 20:01:36.829619: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","W0420 20:01:37.156579 140063296849792 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.74s\n","I0420 20:01:37.631841 140063296849792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.74s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.68s\n","I0420 20:01:38.308171 140063296849792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.68s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.33s\n","I0420 20:01:38.642380 140063296849792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.33s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.32s\n","I0420 20:01:38.967552 140063296849792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.32s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.9s\n","I0420 20:01:40.870698 140063296849792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.9s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","I0420 20:01:40.871568 140063296849792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n","I0420 20:01:40.894047 140063296849792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n","I0420 20:01:40.907917 140063296849792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n","I0420 20:01:40.922076 140063296849792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n","I0420 20:01:41.014416 140063296849792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n","I0420 20:01:41.105619 140063296849792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n","I0420 20:01:41.199314 140063296849792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n","I0420 20:01:41.290887 140063296849792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n","I0420 20:01:41.380467 140063296849792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n","[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n","I0420 20:01:41.407291 140063296849792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","I0420 20:01:41.582653 140063296849792 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I0420 20:01:41.582832 140063296849792 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n","I0420 20:01:41.582904 140063296849792 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n","I0420 20:01:41.585112 140063296849792 efficientnet_model.py:144] round_filter input=32 output=32\n","I0420 20:01:41.600673 140063296849792 efficientnet_model.py:144] round_filter input=32 output=32\n","I0420 20:01:41.600794 140063296849792 efficientnet_model.py:144] round_filter input=16 output=16\n","I0420 20:01:41.654579 140063296849792 efficientnet_model.py:144] round_filter input=16 output=16\n","I0420 20:01:41.654751 140063296849792 efficientnet_model.py:144] round_filter input=24 output=24\n","I0420 20:01:41.793016 140063296849792 efficientnet_model.py:144] round_filter input=24 output=24\n","I0420 20:01:41.793145 140063296849792 efficientnet_model.py:144] round_filter input=40 output=40\n","I0420 20:01:41.931672 140063296849792 efficientnet_model.py:144] round_filter input=40 output=40\n","I0420 20:01:41.931811 140063296849792 efficientnet_model.py:144] round_filter input=80 output=80\n","I0420 20:01:42.146102 140063296849792 efficientnet_model.py:144] round_filter input=80 output=80\n","I0420 20:01:42.146278 140063296849792 efficientnet_model.py:144] round_filter input=112 output=112\n","I0420 20:01:42.349387 140063296849792 efficientnet_model.py:144] round_filter input=112 output=112\n","I0420 20:01:42.349568 140063296849792 efficientnet_model.py:144] round_filter input=192 output=192\n","I0420 20:01:42.776417 140063296849792 efficientnet_model.py:144] round_filter input=192 output=192\n","I0420 20:01:42.776611 140063296849792 efficientnet_model.py:144] round_filter input=320 output=320\n","I0420 20:01:42.842634 140063296849792 efficientnet_model.py:144] round_filter input=1280 output=1280\n","I0420 20:01:42.869993 140063296849792 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0420 20:01:42.919250 140063296849792 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n","I0420 20:01:42.919369 140063296849792 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n","I0420 20:01:42.919416 140063296849792 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n","I0420 20:01:42.920934 140063296849792 efficientnet_model.py:144] round_filter input=32 output=32\n","I0420 20:01:42.934300 140063296849792 efficientnet_model.py:144] round_filter input=32 output=32\n","I0420 20:01:42.934399 140063296849792 efficientnet_model.py:144] round_filter input=16 output=16\n","I0420 20:01:43.042753 140063296849792 efficientnet_model.py:144] round_filter input=16 output=16\n","I0420 20:01:43.042881 140063296849792 efficientnet_model.py:144] round_filter input=24 output=24\n","I0420 20:01:43.255406 140063296849792 efficientnet_model.py:144] round_filter input=24 output=24\n","I0420 20:01:43.255592 140063296849792 efficientnet_model.py:144] round_filter input=40 output=40\n","I0420 20:01:43.461413 140063296849792 efficientnet_model.py:144] round_filter input=40 output=40\n","I0420 20:01:43.461586 140063296849792 efficientnet_model.py:144] round_filter input=80 output=80\n","I0420 20:01:43.737233 140063296849792 efficientnet_model.py:144] round_filter input=80 output=80\n","I0420 20:01:43.737396 140063296849792 efficientnet_model.py:144] round_filter input=112 output=112\n","I0420 20:01:44.014384 140063296849792 efficientnet_model.py:144] round_filter input=112 output=112\n","I0420 20:01:44.014567 140063296849792 efficientnet_model.py:144] round_filter input=192 output=192\n","I0420 20:01:44.367262 140063296849792 efficientnet_model.py:144] round_filter input=192 output=192\n","I0420 20:01:44.367451 140063296849792 efficientnet_model.py:144] round_filter input=320 output=320\n","I0420 20:01:44.507647 140063296849792 efficientnet_model.py:144] round_filter input=1280 output=1280\n","I0420 20:01:44.534964 140063296849792 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0420 20:01:44.594139 140063296849792 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n","I0420 20:01:44.594289 140063296849792 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n","I0420 20:01:44.594361 140063296849792 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n","I0420 20:01:44.596079 140063296849792 efficientnet_model.py:144] round_filter input=32 output=32\n","I0420 20:01:44.609568 140063296849792 efficientnet_model.py:144] round_filter input=32 output=32\n","I0420 20:01:44.609673 140063296849792 efficientnet_model.py:144] round_filter input=16 output=16\n","I0420 20:01:44.718541 140063296849792 efficientnet_model.py:144] round_filter input=16 output=16\n","I0420 20:01:44.718718 140063296849792 efficientnet_model.py:144] round_filter input=24 output=24\n","I0420 20:01:44.928241 140063296849792 efficientnet_model.py:144] round_filter input=24 output=24\n","I0420 20:01:44.928404 140063296849792 efficientnet_model.py:144] round_filter input=40 output=48\n","I0420 20:01:45.142294 140063296849792 efficientnet_model.py:144] round_filter input=40 output=48\n","I0420 20:01:45.142477 140063296849792 efficientnet_model.py:144] round_filter input=80 output=88\n","I0420 20:01:45.421173 140063296849792 efficientnet_model.py:144] round_filter input=80 output=88\n","I0420 20:01:45.421360 140063296849792 efficientnet_model.py:144] round_filter input=112 output=120\n","I0420 20:01:45.697800 140063296849792 efficientnet_model.py:144] round_filter input=112 output=120\n","I0420 20:01:45.697971 140063296849792 efficientnet_model.py:144] round_filter input=192 output=208\n","I0420 20:01:46.044463 140063296849792 efficientnet_model.py:144] round_filter input=192 output=208\n","I0420 20:01:46.044631 140063296849792 efficientnet_model.py:144] round_filter input=320 output=352\n","I0420 20:01:46.184259 140063296849792 efficientnet_model.py:144] round_filter input=1280 output=1408\n","I0420 20:01:46.212519 140063296849792 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0420 20:01:46.270610 140063296849792 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n","I0420 20:01:46.270758 140063296849792 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n","I0420 20:01:46.270826 140063296849792 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n","I0420 20:01:46.272311 140063296849792 efficientnet_model.py:144] round_filter input=32 output=40\n","I0420 20:01:46.286077 140063296849792 efficientnet_model.py:144] round_filter input=32 output=40\n","I0420 20:01:46.286195 140063296849792 efficientnet_model.py:144] round_filter input=16 output=24\n","I0420 20:01:46.592991 140063296849792 efficientnet_model.py:144] round_filter input=16 output=24\n","I0420 20:01:46.593168 140063296849792 efficientnet_model.py:144] round_filter input=24 output=32\n","I0420 20:01:46.799574 140063296849792 efficientnet_model.py:144] round_filter input=24 output=32\n","I0420 20:01:46.799748 140063296849792 efficientnet_model.py:144] round_filter input=40 output=48\n","I0420 20:01:47.008349 140063296849792 efficientnet_model.py:144] round_filter input=40 output=48\n","I0420 20:01:47.008539 140063296849792 efficientnet_model.py:144] round_filter input=80 output=96\n","I0420 20:01:47.360925 140063296849792 efficientnet_model.py:144] round_filter input=80 output=96\n","I0420 20:01:47.361104 140063296849792 efficientnet_model.py:144] round_filter input=112 output=136\n","I0420 20:01:47.705767 140063296849792 efficientnet_model.py:144] round_filter input=112 output=136\n","I0420 20:01:47.705940 140063296849792 efficientnet_model.py:144] round_filter input=192 output=232\n","I0420 20:01:48.125552 140063296849792 efficientnet_model.py:144] round_filter input=192 output=232\n","I0420 20:01:48.125730 140063296849792 efficientnet_model.py:144] round_filter input=320 output=384\n","I0420 20:01:48.266083 140063296849792 efficientnet_model.py:144] round_filter input=1280 output=1536\n","I0420 20:01:48.293060 140063296849792 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0420 20:01:48.354054 140063296849792 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n","I0420 20:01:48.354201 140063296849792 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n","I0420 20:01:48.354271 140063296849792 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n","I0420 20:01:48.356017 140063296849792 efficientnet_model.py:144] round_filter input=32 output=48\n","I0420 20:01:48.370469 140063296849792 efficientnet_model.py:144] round_filter input=32 output=48\n","I0420 20:01:48.370574 140063296849792 efficientnet_model.py:144] round_filter input=16 output=24\n","I0420 20:01:48.481528 140063296849792 efficientnet_model.py:144] round_filter input=16 output=24\n","I0420 20:01:48.481657 140063296849792 efficientnet_model.py:144] round_filter input=24 output=32\n","I0420 20:01:48.761148 140063296849792 efficientnet_model.py:144] round_filter input=24 output=32\n","I0420 20:01:48.761319 140063296849792 efficientnet_model.py:144] round_filter input=40 output=56\n","I0420 20:01:49.038032 140063296849792 efficientnet_model.py:144] round_filter input=40 output=56\n","I0420 20:01:49.038204 140063296849792 efficientnet_model.py:144] round_filter input=80 output=112\n","I0420 20:01:49.450357 140063296849792 efficientnet_model.py:144] round_filter input=80 output=112\n","I0420 20:01:49.450551 140063296849792 efficientnet_model.py:144] round_filter input=112 output=160\n","I0420 20:01:49.862639 140063296849792 efficientnet_model.py:144] round_filter input=112 output=160\n","I0420 20:01:49.862825 140063296849792 efficientnet_model.py:144] round_filter input=192 output=272\n","I0420 20:01:50.436968 140063296849792 efficientnet_model.py:144] round_filter input=192 output=272\n","I0420 20:01:50.437149 140063296849792 efficientnet_model.py:144] round_filter input=320 output=448\n","I0420 20:01:50.574038 140063296849792 efficientnet_model.py:144] round_filter input=1280 output=1792\n","I0420 20:01:50.600630 140063296849792 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0420 20:01:50.876936 140063296849792 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n","I0420 20:01:50.877102 140063296849792 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n","I0420 20:01:50.877158 140063296849792 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n","I0420 20:01:50.878709 140063296849792 efficientnet_model.py:144] round_filter input=32 output=48\n","I0420 20:01:50.893056 140063296849792 efficientnet_model.py:144] round_filter input=32 output=48\n","I0420 20:01:50.893168 140063296849792 efficientnet_model.py:144] round_filter input=16 output=24\n","I0420 20:01:51.062428 140063296849792 efficientnet_model.py:144] round_filter input=16 output=24\n","I0420 20:01:51.062580 140063296849792 efficientnet_model.py:144] round_filter input=24 output=40\n","I0420 20:01:51.408156 140063296849792 efficientnet_model.py:144] round_filter input=24 output=40\n","I0420 20:01:51.408335 140063296849792 efficientnet_model.py:144] round_filter input=40 output=64\n","I0420 20:01:51.749107 140063296849792 efficientnet_model.py:144] round_filter input=40 output=64\n","I0420 20:01:51.749281 140063296849792 efficientnet_model.py:144] round_filter input=80 output=128\n","I0420 20:01:52.228555 140063296849792 efficientnet_model.py:144] round_filter input=80 output=128\n","I0420 20:01:52.228718 140063296849792 efficientnet_model.py:144] round_filter input=112 output=176\n","I0420 20:01:52.700150 140063296849792 efficientnet_model.py:144] round_filter input=112 output=176\n","I0420 20:01:52.700308 140063296849792 efficientnet_model.py:144] round_filter input=192 output=304\n","I0420 20:01:53.346374 140063296849792 efficientnet_model.py:144] round_filter input=192 output=304\n","I0420 20:01:53.346569 140063296849792 efficientnet_model.py:144] round_filter input=320 output=512\n","I0420 20:01:53.556145 140063296849792 efficientnet_model.py:144] round_filter input=1280 output=2048\n","I0420 20:01:53.582221 140063296849792 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0420 20:01:53.666952 140063296849792 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n","I0420 20:01:53.667095 140063296849792 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n","I0420 20:01:53.667148 140063296849792 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n","I0420 20:01:53.668691 140063296849792 efficientnet_model.py:144] round_filter input=32 output=56\n","I0420 20:01:53.682799 140063296849792 efficientnet_model.py:144] round_filter input=32 output=56\n","I0420 20:01:53.682901 140063296849792 efficientnet_model.py:144] round_filter input=16 output=32\n","I0420 20:01:53.850200 140063296849792 efficientnet_model.py:144] round_filter input=16 output=32\n","I0420 20:01:53.850342 140063296849792 efficientnet_model.py:144] round_filter input=24 output=40\n","I0420 20:01:54.266412 140063296849792 efficientnet_model.py:144] round_filter input=24 output=40\n","I0420 20:01:54.266595 140063296849792 efficientnet_model.py:144] round_filter input=40 output=72\n","I0420 20:01:54.682856 140063296849792 efficientnet_model.py:144] round_filter input=40 output=72\n","I0420 20:01:54.683031 140063296849792 efficientnet_model.py:144] round_filter input=80 output=144\n","I0420 20:01:55.259049 140063296849792 efficientnet_model.py:144] round_filter input=80 output=144\n","I0420 20:01:55.259215 140063296849792 efficientnet_model.py:144] round_filter input=112 output=200\n","I0420 20:01:56.083740 140063296849792 efficientnet_model.py:144] round_filter input=112 output=200\n","I0420 20:01:56.083949 140063296849792 efficientnet_model.py:144] round_filter input=192 output=344\n","I0420 20:01:56.885092 140063296849792 efficientnet_model.py:144] round_filter input=192 output=344\n","I0420 20:01:56.885258 140063296849792 efficientnet_model.py:144] round_filter input=320 output=576\n","I0420 20:01:57.104360 140063296849792 efficientnet_model.py:144] round_filter input=1280 output=2304\n","I0420 20:01:57.134051 140063296849792 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0420 20:01:57.241966 140063296849792 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n","I0420 20:01:57.242121 140063296849792 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n","I0420 20:01:57.242182 140063296849792 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n","I0420 20:01:57.243896 140063296849792 efficientnet_model.py:144] round_filter input=32 output=64\n","I0420 20:01:57.259407 140063296849792 efficientnet_model.py:144] round_filter input=32 output=64\n","I0420 20:01:57.259539 140063296849792 efficientnet_model.py:144] round_filter input=16 output=32\n","I0420 20:01:57.495604 140063296849792 efficientnet_model.py:144] round_filter input=16 output=32\n","I0420 20:01:57.495766 140063296849792 efficientnet_model.py:144] round_filter input=24 output=48\n","I0420 20:01:57.978282 140063296849792 efficientnet_model.py:144] round_filter input=24 output=48\n","I0420 20:01:57.978454 140063296849792 efficientnet_model.py:144] round_filter input=40 output=80\n","I0420 20:01:58.494881 140063296849792 efficientnet_model.py:144] round_filter input=40 output=80\n","I0420 20:01:58.495066 140063296849792 efficientnet_model.py:144] round_filter input=80 output=160\n","I0420 20:01:59.190107 140063296849792 efficientnet_model.py:144] round_filter input=80 output=160\n","I0420 20:01:59.190272 140063296849792 efficientnet_model.py:144] round_filter input=112 output=224\n","I0420 20:01:59.880432 140063296849792 efficientnet_model.py:144] round_filter input=112 output=224\n","I0420 20:01:59.880609 140063296849792 efficientnet_model.py:144] round_filter input=192 output=384\n","I0420 20:02:00.834301 140063296849792 efficientnet_model.py:144] round_filter input=192 output=384\n","I0420 20:02:00.834471 140063296849792 efficientnet_model.py:144] round_filter input=320 output=640\n","I0420 20:02:01.397640 140063296849792 efficientnet_model.py:144] round_filter input=1280 output=2560\n","I0420 20:02:01.424861 140063296849792 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 20.13s\n","I0420 20:02:01.538913 140063296849792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 20.13s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","I0420 20:02:01.545617 140063296849792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","I0420 20:02:01.547146 140063296849792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","I0420 20:02:01.547639 140063296849792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","I0420 20:02:01.549110 140063296849792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTF2Test.test_session\n","[  SKIPPED ] ModelBuilderTF2Test.test_session\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","I0420 20:02:01.550317 140063296849792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","I0420 20:02:01.550716 140063296849792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","I0420 20:02:01.551581 140063296849792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 24 tests in 25.658s\n","\n","OK (skipped=1)\n"]}]},{"cell_type":"markdown","source":["### **Setting up data**"],"metadata":{"id":"i-lBPdPErC5B"}},{"cell_type":"code","source":["cd .."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X0Aaza2priw7","executionInfo":{"status":"ok","timestamp":1650484923219,"user_tz":240,"elapsed":64,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"c79970fc-4e36-4f5c-8f6e-004551cd65c6"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/models\n"]}]},{"cell_type":"code","source":["cd .."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z5BGqevltapt","executionInfo":{"status":"ok","timestamp":1650484923221,"user_tz":240,"elapsed":50,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"47fff134-59f2-42fa-e84c-e589c1d29002"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"yvxg8CIfsKvN","executionInfo":{"status":"ok","timestamp":1650484923223,"user_tz":240,"elapsed":44,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"d0fc03b1-5f24-4b38-8fdb-aedd8fb2f85e"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["!mkdir training"],"metadata":{"id":"oPX70fBArKTZ","executionInfo":{"status":"ok","timestamp":1650484923225,"user_tz":240,"elapsed":40,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["cd training"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PGiKGnslttt0","executionInfo":{"status":"ok","timestamp":1650484923227,"user_tz":240,"elapsed":39,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"ad643a04-5a3d-4514-a083-62b4745c6ba0"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/training\n"]}]},{"cell_type":"code","source":["!mkdir models\n","!mkdir exported_models\n","!mkdir pre-trained-models\n","!mkdir annotations"],"metadata":{"id":"WbYx-tUEtu79","executionInfo":{"status":"ok","timestamp":1650484923530,"user_tz":240,"elapsed":335,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["cd exported_models"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fCl2V2GPhwLO","executionInfo":{"status":"ok","timestamp":1650484923532,"user_tz":240,"elapsed":19,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"c731fc17-0324-453e-856f-21ea5c8a44b2"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/training/exported_models\n"]}]},{"cell_type":"code","source":["!mkdir my_model"],"metadata":{"id":"9x2x1tkuhzYp","executionInfo":{"status":"ok","timestamp":1650484923709,"user_tz":240,"elapsed":187,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["cd .."],"metadata":{"id":"m2CbBwdpiB84","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650484923710,"user_tz":240,"elapsed":19,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"bb897937-14f1-4182-b8a7-b048571dfcb2"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/training\n"]}]},{"cell_type":"code","metadata":{"id":"gL4BBRoZuWr8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650484923861,"user_tz":240,"elapsed":10,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"486d6181-b8a0-40bd-cb12-4990ea21542c"},"source":["cd /content/training/pre-trained-models"],"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/training/pre-trained-models\n"]}]},{"cell_type":"code","metadata":{"id":"MItGLVY3uWu8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650484925703,"user_tz":240,"elapsed":1850,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"c8b81a4b-6015-4cd6-f8b5-f3f307ee31f9"},"source":["!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz"],"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-04-20 20:02:03--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 172.217.203.128, 2607:f8b0:400c:c07::80\n","Connecting to download.tensorflow.org (download.tensorflow.org)|172.217.203.128|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 386527459 (369M) [application/x-tar]\n","Saving to: ‘ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz’\n","\n","ssd_resnet101_v1_fp 100%[===================>] 368.62M   254MB/s    in 1.5s    \n","\n","2022-04-20 20:02:05 (254 MB/s) - ‘ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz’ saved [386527459/386527459]\n","\n"]}]},{"cell_type":"code","metadata":{"id":"tzlPcDPLuWye","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650484930722,"user_tz":240,"elapsed":5037,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"1c57838d-e5f2-4f8a-a7ab-838ed63f5aac"},"source":["!tar -xvf ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz"],"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/checkpoint\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/pipeline.config\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/saved_model.pb\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/assets/\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"]}]},{"cell_type":"code","metadata":{"id":"Vf49zVcAtNJB","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1650484930724,"user_tz":240,"elapsed":62,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"bd4238ad-007c-4619-ef39-ff93cb9dc6b8"},"source":["pwd"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/training/pre-trained-models'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"MFA0L4rmyGae","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650484930726,"user_tz":240,"elapsed":52,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"7ee167b7-6490-4dc6-d91d-6ccc2fda87f4"},"source":["cd /content/training"],"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/training\n"]}]},{"cell_type":"code","metadata":{"id":"Pxst7lPT0Sby","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650484930879,"user_tz":240,"elapsed":182,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"e120018f-2043-4f67-c1c1-f294c6b070ef"},"source":["ls"],"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mannotations\u001b[0m/  \u001b[01;34mexported_models\u001b[0m/  \u001b[01;34mmodels\u001b[0m/  \u001b[01;34mpre-trained-models\u001b[0m/\n"]}]},{"cell_type":"code","metadata":{"id":"hU2lVZfzyuar","executionInfo":{"status":"ok","timestamp":1650484935622,"user_tz":240,"elapsed":310,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}}},"source":["# # GENERATE TF RECORDS.\n","\n","# # Create train data:\n","# !python $REQUIRED_FILES_DRIVE_PATH/generate_tfrecord.py \\\n","# -x $TRAIN_IMAGES_DRIVE_PATH \\\n","# -l $REQUIRED_FILES_DRIVE_PATH/label_map.pbtxt \\\n","# -o /content/training/annotations/train.record\n","\n","# # Create test data:\n","# !python $REQUIRED_FILES_DRIVE_PATH/generate_tfrecord.py \\\n","# -x $TEST_IMAGES_DRIVE_PATH \\\n","# -l $REQUIRED_FILES_DRIVE_PATH/label_map.pbtxt \\\n","# -o /content/training/annotations/test.record"],"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":["### **Configure training job**"],"metadata":{"id":"KYlcgCo-zqA2"}},{"cell_type":"markdown","source":["**Copy the config file from pretrained-models folder and edit as required.**"],"metadata":{"id":"mtdLkEOb0Nqk"}},{"cell_type":"code","metadata":{"id":"MfHABHxi56kM","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1650484938079,"user_tz":240,"elapsed":438,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"d284b8ea-fefc-4378-ddda-f8e0fcff0165"},"source":["pwd"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/training'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"oQO8P8xLy6bS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650484938575,"user_tz":240,"elapsed":247,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"5c388e9f-dae0-4a55-f237-fbff7aae72e3"},"source":["ls"],"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mannotations\u001b[0m/  \u001b[01;34mexported_models\u001b[0m/  \u001b[01;34mmodels\u001b[0m/  \u001b[01;34mpre-trained-models\u001b[0m/\n"]}]},{"cell_type":"code","source":["cd models"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u4zv6Vzn0_9w","executionInfo":{"status":"ok","timestamp":1650484939774,"user_tz":240,"elapsed":251,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"41a6ed09-8052-444d-b394-948b0b2b43a0"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/training/models\n"]}]},{"cell_type":"code","source":["!mkdir my-pretrained-model"],"metadata":{"id":"JiBitIDC1Bwe","executionInfo":{"status":"ok","timestamp":1650484941131,"user_tz":240,"elapsed":329,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XYk5pucM1Qqb","executionInfo":{"status":"ok","timestamp":1650484942791,"user_tz":240,"elapsed":335,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"50f3751d-ed33-4431-ee42-8bef91d2f65d"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mmy-pretrained-model\u001b[0m/\n"]}]},{"cell_type":"code","source":["cd .."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w4q7HvX91Eit","executionInfo":{"status":"ok","timestamp":1650484944863,"user_tz":240,"elapsed":155,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"e7fad175-7284-427a-e67c-5f53dc8a676a"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/training\n"]}]},{"cell_type":"code","source":["# Change the name of the model, if you are using a different pretrained model.\n","\n","# !cp pre-trained-models/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/pipeline.config models/my-pretrained-model\n","\n","!cp -r $REQUIRED_FILES_DRIVE_PATH/pipeline.config models/my-pretrained-model"],"metadata":{"id":"o4qZ8Ymy0ot7","executionInfo":{"status":"ok","timestamp":1650484953577,"user_tz":240,"elapsed":1408,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["cd models/my-pretrained-model/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kkhtk8sg1Uti","executionInfo":{"status":"ok","timestamp":1650484955813,"user_tz":240,"elapsed":159,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"ce0e85bd-e2ac-4d4a-d215-6498da5fecb9"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/training/models/my-pretrained-model\n"]}]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LceTJ2aO1bpr","executionInfo":{"status":"ok","timestamp":1650484958196,"user_tz":240,"elapsed":380,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"b6bd7201-1c27-4a83-bc84-64def23e4e8c"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["pipeline.config\n"]}]},{"cell_type":"code","source":["cd .."],"metadata":{"id":"Oz6cvH7nRBn1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650484960101,"user_tz":240,"elapsed":11,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"b2007898-8b68-40fc-fedb-3a0ea70ee4a8"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/training/models\n"]}]},{"cell_type":"code","source":["cd .."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xKVMYXzm20w-","executionInfo":{"status":"ok","timestamp":1650484962148,"user_tz":240,"elapsed":382,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"093d3208-94ee-4524-aa57-89f1b6fd724f"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/training\n"]}]},{"cell_type":"code","source":["# Copy labels_map.txt to annotations folder from drive.\n","\n","!cp -r $REQUIRED_FILES_DRIVE_PATH/label_map.pbtxt annotations/\n","\n","# Copy tfrecords from drive that is generated locally to here.\n","\n","!cp -r $REQUIRED_FILES_DRIVE_PATH/train.record annotations/\n","!cp -r $REQUIRED_FILES_DRIVE_PATH/test.record annotations/"],"metadata":{"id":"BR5LuM7-25S2","executionInfo":{"status":"ok","timestamp":1650484971560,"user_tz":240,"elapsed":3537,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["# Copy other required files from drive. (originally taken from git repo of TF OD API)\n","\n","!cp $REQUIRED_FILES_DRIVE_PATH/model_main_tf2.py .\n","!cp $REQUIRED_FILES_DRIVE_PATH/exporter_main_v2.py .\n","!cp $REQUIRED_FILES_DRIVE_PATH/export_tflite_graph_tf2.py ."],"metadata":{"id":"QjOA8B1sfhqC","executionInfo":{"status":"ok","timestamp":1650484978222,"user_tz":240,"elapsed":958,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}}},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":["**PLEASE EDIT YOUR NEW CONFIG FILE**"],"metadata":{"id":"TxsDFiWs1ll_"}},{"cell_type":"code","source":["!pip uninstall opencv-python\n","!pip uninstall opencv-python-headless"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rZ3TVjZjggzg","executionInfo":{"status":"ok","timestamp":1650485117965,"user_tz":240,"elapsed":12123,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"a044d839-59c3-4023-a7f8-390022dc594c"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: opencv-python 4.1.2.30\n","Uninstalling opencv-python-4.1.2.30:\n","  Would remove:\n","    /usr/local/lib/python3.7/dist-packages/cv2/*\n","    /usr/local/lib/python3.7/dist-packages/opencv_python-4.1.2.30.dist-info/*\n","  Would not remove (might be manually added):\n","    /usr/local/lib/python3.7/dist-packages/cv2/config-3.py\n","    /usr/local/lib/python3.7/dist-packages/cv2/config.py\n","    /usr/local/lib/python3.7/dist-packages/cv2/cv2.abi3.so\n","    /usr/local/lib/python3.7/dist-packages/cv2/gapi/__init__.py\n","    /usr/local/lib/python3.7/dist-packages/cv2/load_config_py2.py\n","    /usr/local/lib/python3.7/dist-packages/cv2/load_config_py3.py\n","    /usr/local/lib/python3.7/dist-packages/cv2/mat_wrapper/__init__.py\n","    /usr/local/lib/python3.7/dist-packages/cv2/misc/__init__.py\n","    /usr/local/lib/python3.7/dist-packages/cv2/misc/version.py\n","    /usr/local/lib/python3.7/dist-packages/cv2/utils/__init__.py\n","    /usr/local/lib/python3.7/dist-packages/cv2/version.py\n","Proceed (y/n)? y\n","  Successfully uninstalled opencv-python-4.1.2.30\n","Found existing installation: opencv-python-headless 4.5.5.64\n","Uninstalling opencv-python-headless-4.5.5.64:\n","  Would remove:\n","    /usr/local/lib/python3.7/dist-packages/cv2/config-3.py\n","    /usr/local/lib/python3.7/dist-packages/cv2/config.py\n","    /usr/local/lib/python3.7/dist-packages/cv2/cv2.abi3.so\n","    /usr/local/lib/python3.7/dist-packages/cv2/gapi/*\n","    /usr/local/lib/python3.7/dist-packages/cv2/load_config_py2.py\n","    /usr/local/lib/python3.7/dist-packages/cv2/load_config_py3.py\n","    /usr/local/lib/python3.7/dist-packages/cv2/mat_wrapper/*\n","    /usr/local/lib/python3.7/dist-packages/cv2/misc/*\n","    /usr/local/lib/python3.7/dist-packages/cv2/utils/*\n","    /usr/local/lib/python3.7/dist-packages/cv2/version.py\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless-4.5.5.64.dist-info/*\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavcodec-65fa80df.so.58.134.100\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavformat-8ef5c7db.so.58.76.100\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavutil-9c768859.so.56.70.100\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libbz2-a273e504.so.1.0.6\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libcrypto-09fe7800.so.1.1\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libgfortran-91cc3cb1.so.3.0.0\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libopenblas-r0-f650aae0.3.3.so\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libquadmath-96973f99.so.0.0.0\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libssl-b92f8066.so.1.1\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libswresample-99364a1c.so.3.9.100\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libswscale-e6451464.so.5.9.100\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libvpx-1016051d.so.7.0.0\n","Proceed (y/n)? y\n","  Successfully uninstalled opencv-python-headless-4.5.5.64\n"]}]},{"cell_type":"code","source":["!pip install opencv-python==4.1.2.30\n","!pip install opencv-python-headless==4.1.2.30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WL5kqB7ngt1q","executionInfo":{"status":"ok","timestamp":1650485133115,"user_tz":240,"elapsed":11432,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"c079da3c-2461-4d31-b045-1eebdfdd30bd"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting opencv-python==4.1.2.30\n","  Downloading opencv_python-4.1.2.30-cp37-cp37m-manylinux1_x86_64.whl (28.3 MB)\n","\u001b[K     |████████████████████████████████| 28.3 MB 1.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==4.1.2.30) (1.21.6)\n","Installing collected packages: opencv-python\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed opencv-python-4.1.2.30\n","Collecting opencv-python-headless==4.1.2.30\n","  Downloading opencv_python_headless-4.1.2.30-cp37-cp37m-manylinux1_x86_64.whl (21.8 MB)\n","\u001b[K     |████████████████████████████████| 21.8 MB 4.9 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.1.2.30) (1.21.6)\n","Installing collected packages: opencv-python-headless\n","Successfully installed opencv-python-headless-4.1.2.30\n"]}]},{"cell_type":"code","source":["import cv2\n","cv2.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"crc47-PNg8Fk","executionInfo":{"status":"ok","timestamp":1650485137442,"user_tz":240,"elapsed":12,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"b61812e1-25b6-4923-c97e-7f80f57b5d84"},"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'4.1.2'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"OYPGVsitfyGD","executionInfo":{"status":"ok","timestamp":1650485140994,"user_tz":240,"elapsed":12,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"a68073bd-d2c5-4108-afce-b5aa1e8bfa79"},"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/training'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":55}]},{"cell_type":"code","metadata":{"id":"pNVwlSCq9pr1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650494941702,"user_tz":240,"elapsed":9787538,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"4ac5bbad-4ee6-4b62-b5a1-92d3f1d09611"},"source":["!python model_main_tf2.py --model_dir=/content/training/models/my-pretrained-model \\\n","--pipeline_config_path=/content/training/models/my-pretrained-model/pipeline.config"],"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-04-20 20:05:57.950615: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","I0420 20:05:57.956419 139650086602624 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","INFO:tensorflow:Maybe overwriting train_steps: None\n","I0420 20:05:57.960153 139650086602624 config_util.py:552] Maybe overwriting train_steps: None\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0420 20:05:57.960298 139650086602624 config_util.py:552] Maybe overwriting use_bfloat16: False\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","W0420 20:05:58.104726 139650086602624 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","INFO:tensorflow:Reading unweighted datasets: ['/content/training/annotations/train.record']\n","I0420 20:05:58.110048 139650086602624 dataset_builder.py:162] Reading unweighted datasets: ['/content/training/annotations/train.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/training/annotations/train.record']\n","I0420 20:05:58.110224 139650086602624 dataset_builder.py:79] Reading record datasets for input file: ['/content/training/annotations/train.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0420 20:05:58.110285 139650086602624 dataset_builder.py:80] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0420 20:05:58.110335 139650086602624 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","W0420 20:05:58.112480 139650086602624 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0420 20:05:58.131429 139650086602624 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0420 20:06:05.006519 139650086602624 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W0420 20:06:07.931362 139650086602624 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0420 20:06:09.766027 139650086602624 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0420 20:06:41.925193 139650086602624 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0420 20:06:41.926478 139650086602624 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0420 20:06:41.928596 139650086602624 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0420 20:06:41.929522 139650086602624 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0420 20:06:41.931586 139650086602624 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0420 20:06:41.932497 139650086602624 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0420 20:06:41.934980 139650086602624 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0420 20:06:41.935885 139650086602624 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0420 20:06:41.937699 139650086602624 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0420 20:06:41.938633 139650086602624 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","W0420 20:06:42.947765 139644952266496 deprecation.py:547] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","INFO:tensorflow:Step 100 per-step time 1.493s\n","I0420 20:09:11.875236 139650086602624 model_lib_v2.py:707] Step 100 per-step time 1.493s\n","INFO:tensorflow:{'Loss/classification_loss': 0.67880094,\n"," 'Loss/localization_loss': 0.20012173,\n"," 'Loss/regularization_loss': 0.30439377,\n"," 'Loss/total_loss': 1.1833165,\n"," 'learning_rate': 0.0159997}\n","I0420 20:09:11.875594 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.67880094,\n"," 'Loss/localization_loss': 0.20012173,\n"," 'Loss/regularization_loss': 0.30439377,\n"," 'Loss/total_loss': 1.1833165,\n"," 'learning_rate': 0.0159997}\n","INFO:tensorflow:Step 200 per-step time 0.970s\n","I0420 20:10:48.846493 139650086602624 model_lib_v2.py:707] Step 200 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 0.45438564,\n"," 'Loss/localization_loss': 0.13579766,\n"," 'Loss/regularization_loss': 0.30626148,\n"," 'Loss/total_loss': 0.8964448,\n"," 'learning_rate': 0.0186664}\n","I0420 20:10:48.846805 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.45438564,\n"," 'Loss/localization_loss': 0.13579766,\n"," 'Loss/regularization_loss': 0.30626148,\n"," 'Loss/total_loss': 0.8964448,\n"," 'learning_rate': 0.0186664}\n","INFO:tensorflow:Step 300 per-step time 0.970s\n","I0420 20:12:25.892110 139650086602624 model_lib_v2.py:707] Step 300 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 0.4399779,\n"," 'Loss/localization_loss': 0.11943323,\n"," 'Loss/regularization_loss': 0.31713292,\n"," 'Loss/total_loss': 0.8765441,\n"," 'learning_rate': 0.0213331}\n","I0420 20:12:25.892410 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.4399779,\n"," 'Loss/localization_loss': 0.11943323,\n"," 'Loss/regularization_loss': 0.31713292,\n"," 'Loss/total_loss': 0.8765441,\n"," 'learning_rate': 0.0213331}\n","INFO:tensorflow:Step 400 per-step time 0.971s\n","I0420 20:14:02.968002 139650086602624 model_lib_v2.py:707] Step 400 per-step time 0.971s\n","INFO:tensorflow:{'Loss/classification_loss': 1.2934157,\n"," 'Loss/localization_loss': 0.7346851,\n"," 'Loss/regularization_loss': 9.288798,\n"," 'Loss/total_loss': 11.316899,\n"," 'learning_rate': 0.023999799}\n","I0420 20:14:02.968334 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 1.2934157,\n"," 'Loss/localization_loss': 0.7346851,\n"," 'Loss/regularization_loss': 9.288798,\n"," 'Loss/total_loss': 11.316899,\n"," 'learning_rate': 0.023999799}\n","INFO:tensorflow:Step 500 per-step time 0.971s\n","I0420 20:15:40.031229 139650086602624 model_lib_v2.py:707] Step 500 per-step time 0.971s\n","INFO:tensorflow:{'Loss/classification_loss': 1.1786005,\n"," 'Loss/localization_loss': 0.57955897,\n"," 'Loss/regularization_loss': 11.021745,\n"," 'Loss/total_loss': 12.779904,\n"," 'learning_rate': 0.0266665}\n","I0420 20:15:40.031589 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 1.1786005,\n"," 'Loss/localization_loss': 0.57955897,\n"," 'Loss/regularization_loss': 11.021745,\n"," 'Loss/total_loss': 12.779904,\n"," 'learning_rate': 0.0266665}\n","INFO:tensorflow:Step 600 per-step time 0.971s\n","I0420 20:17:17.102783 139650086602624 model_lib_v2.py:707] Step 600 per-step time 0.971s\n","INFO:tensorflow:{'Loss/classification_loss': 1.0778787,\n"," 'Loss/localization_loss': 0.61132234,\n"," 'Loss/regularization_loss': 10.864624,\n"," 'Loss/total_loss': 12.553825,\n"," 'learning_rate': 0.0293332}\n","I0420 20:17:17.103133 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 1.0778787,\n"," 'Loss/localization_loss': 0.61132234,\n"," 'Loss/regularization_loss': 10.864624,\n"," 'Loss/total_loss': 12.553825,\n"," 'learning_rate': 0.0293332}\n","INFO:tensorflow:Step 700 per-step time 0.972s\n","I0420 20:18:54.302348 139650086602624 model_lib_v2.py:707] Step 700 per-step time 0.972s\n","INFO:tensorflow:{'Loss/classification_loss': 1.0321766,\n"," 'Loss/localization_loss': 0.4958711,\n"," 'Loss/regularization_loss': 10.614745,\n"," 'Loss/total_loss': 12.142793,\n"," 'learning_rate': 0.0319999}\n","I0420 20:18:54.302673 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 1.0321766,\n"," 'Loss/localization_loss': 0.4958711,\n"," 'Loss/regularization_loss': 10.614745,\n"," 'Loss/total_loss': 12.142793,\n"," 'learning_rate': 0.0319999}\n","INFO:tensorflow:Step 800 per-step time 0.971s\n","I0420 20:20:31.353978 139650086602624 model_lib_v2.py:707] Step 800 per-step time 0.971s\n","INFO:tensorflow:{'Loss/classification_loss': 1.0508984,\n"," 'Loss/localization_loss': 0.5689965,\n"," 'Loss/regularization_loss': 10.730198,\n"," 'Loss/total_loss': 12.350093,\n"," 'learning_rate': 0.034666598}\n","I0420 20:20:31.354269 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 1.0508984,\n"," 'Loss/localization_loss': 0.5689965,\n"," 'Loss/regularization_loss': 10.730198,\n"," 'Loss/total_loss': 12.350093,\n"," 'learning_rate': 0.034666598}\n","INFO:tensorflow:Step 900 per-step time 0.971s\n","I0420 20:22:08.444275 139650086602624 model_lib_v2.py:707] Step 900 per-step time 0.971s\n","INFO:tensorflow:{'Loss/classification_loss': 0.9702003,\n"," 'Loss/localization_loss': 0.36104468,\n"," 'Loss/regularization_loss': 10.431503,\n"," 'Loss/total_loss': 11.762749,\n"," 'learning_rate': 0.037333302}\n","I0420 20:22:08.444616 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.9702003,\n"," 'Loss/localization_loss': 0.36104468,\n"," 'Loss/regularization_loss': 10.431503,\n"," 'Loss/total_loss': 11.762749,\n"," 'learning_rate': 0.037333302}\n","INFO:tensorflow:Step 1000 per-step time 0.970s\n","I0420 20:23:45.477887 139650086602624 model_lib_v2.py:707] Step 1000 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 0.8999353,\n"," 'Loss/localization_loss': 0.43285275,\n"," 'Loss/regularization_loss': 10.120539,\n"," 'Loss/total_loss': 11.453327,\n"," 'learning_rate': 0.04}\n","I0420 20:23:45.478194 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.8999353,\n"," 'Loss/localization_loss': 0.43285275,\n"," 'Loss/regularization_loss': 10.120539,\n"," 'Loss/total_loss': 11.453327,\n"," 'learning_rate': 0.04}\n","INFO:tensorflow:Step 1100 per-step time 0.986s\n","I0420 20:25:24.065369 139650086602624 model_lib_v2.py:707] Step 1100 per-step time 0.986s\n","INFO:tensorflow:{'Loss/classification_loss': 0.6842552,\n"," 'Loss/localization_loss': 0.3719908,\n"," 'Loss/regularization_loss': 9.807352,\n"," 'Loss/total_loss': 10.863598,\n"," 'learning_rate': 0.039987817}\n","I0420 20:25:24.065716 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.6842552,\n"," 'Loss/localization_loss': 0.3719908,\n"," 'Loss/regularization_loss': 9.807352,\n"," 'Loss/total_loss': 10.863598,\n"," 'learning_rate': 0.039987817}\n","INFO:tensorflow:Step 1200 per-step time 0.970s\n","I0420 20:27:01.079468 139650086602624 model_lib_v2.py:707] Step 1200 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 1.0205212,\n"," 'Loss/localization_loss': 0.47054544,\n"," 'Loss/regularization_loss': 9.501637,\n"," 'Loss/total_loss': 10.992704,\n"," 'learning_rate': 0.03995128}\n","I0420 20:27:01.079813 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 1.0205212,\n"," 'Loss/localization_loss': 0.47054544,\n"," 'Loss/regularization_loss': 9.501637,\n"," 'Loss/total_loss': 10.992704,\n"," 'learning_rate': 0.03995128}\n","INFO:tensorflow:Step 1300 per-step time 0.971s\n","I0420 20:28:38.213541 139650086602624 model_lib_v2.py:707] Step 1300 per-step time 0.971s\n","INFO:tensorflow:{'Loss/classification_loss': 0.85046875,\n"," 'Loss/localization_loss': 0.38617098,\n"," 'Loss/regularization_loss': 9.207747,\n"," 'Loss/total_loss': 10.444387,\n"," 'learning_rate': 0.039890435}\n","I0420 20:28:38.213862 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.85046875,\n"," 'Loss/localization_loss': 0.38617098,\n"," 'Loss/regularization_loss': 9.207747,\n"," 'Loss/total_loss': 10.444387,\n"," 'learning_rate': 0.039890435}\n","INFO:tensorflow:Step 1400 per-step time 0.970s\n","I0420 20:30:15.168209 139650086602624 model_lib_v2.py:707] Step 1400 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 0.7418859,\n"," 'Loss/localization_loss': 0.37394893,\n"," 'Loss/regularization_loss': 8.924342,\n"," 'Loss/total_loss': 10.040177,\n"," 'learning_rate': 0.03980536}\n","I0420 20:30:15.168534 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.7418859,\n"," 'Loss/localization_loss': 0.37394893,\n"," 'Loss/regularization_loss': 8.924342,\n"," 'Loss/total_loss': 10.040177,\n"," 'learning_rate': 0.03980536}\n","INFO:tensorflow:Step 1500 per-step time 0.970s\n","I0420 20:31:52.181819 139650086602624 model_lib_v2.py:707] Step 1500 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 0.5898183,\n"," 'Loss/localization_loss': 0.3293483,\n"," 'Loss/regularization_loss': 8.649401,\n"," 'Loss/total_loss': 9.568567,\n"," 'learning_rate': 0.039696153}\n","I0420 20:31:52.182111 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.5898183,\n"," 'Loss/localization_loss': 0.3293483,\n"," 'Loss/regularization_loss': 8.649401,\n"," 'Loss/total_loss': 9.568567,\n"," 'learning_rate': 0.039696153}\n","INFO:tensorflow:Step 1600 per-step time 0.969s\n","I0420 20:33:29.057733 139650086602624 model_lib_v2.py:707] Step 1600 per-step time 0.969s\n","INFO:tensorflow:{'Loss/classification_loss': 0.60174435,\n"," 'Loss/localization_loss': 0.15055795,\n"," 'Loss/regularization_loss': 8.3838625,\n"," 'Loss/total_loss': 9.136165,\n"," 'learning_rate': 0.03956295}\n","I0420 20:33:29.058065 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.60174435,\n"," 'Loss/localization_loss': 0.15055795,\n"," 'Loss/regularization_loss': 8.3838625,\n"," 'Loss/total_loss': 9.136165,\n"," 'learning_rate': 0.03956295}\n","INFO:tensorflow:Step 1700 per-step time 0.969s\n","I0420 20:35:05.963754 139650086602624 model_lib_v2.py:707] Step 1700 per-step time 0.969s\n","INFO:tensorflow:{'Loss/classification_loss': 0.64910096,\n"," 'Loss/localization_loss': 0.23458144,\n"," 'Loss/regularization_loss': 8.126241,\n"," 'Loss/total_loss': 9.009923,\n"," 'learning_rate': 0.039405912}\n","I0420 20:35:05.964060 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.64910096,\n"," 'Loss/localization_loss': 0.23458144,\n"," 'Loss/regularization_loss': 8.126241,\n"," 'Loss/total_loss': 9.009923,\n"," 'learning_rate': 0.039405912}\n","INFO:tensorflow:Step 1800 per-step time 0.970s\n","I0420 20:36:42.922784 139650086602624 model_lib_v2.py:707] Step 1800 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 0.4708298,\n"," 'Loss/localization_loss': 0.18113346,\n"," 'Loss/regularization_loss': 7.878233,\n"," 'Loss/total_loss': 8.530196,\n"," 'learning_rate': 0.039225236}\n","I0420 20:36:42.923082 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.4708298,\n"," 'Loss/localization_loss': 0.18113346,\n"," 'Loss/regularization_loss': 7.878233,\n"," 'Loss/total_loss': 8.530196,\n"," 'learning_rate': 0.039225236}\n","INFO:tensorflow:Step 1900 per-step time 0.970s\n","I0420 20:38:19.927372 139650086602624 model_lib_v2.py:707] Step 1900 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 0.58568144,\n"," 'Loss/localization_loss': 0.3733784,\n"," 'Loss/regularization_loss': 7.6388702,\n"," 'Loss/total_loss': 8.59793,\n"," 'learning_rate': 0.039021127}\n","I0420 20:38:19.927701 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.58568144,\n"," 'Loss/localization_loss': 0.3733784,\n"," 'Loss/regularization_loss': 7.6388702,\n"," 'Loss/total_loss': 8.59793,\n"," 'learning_rate': 0.039021127}\n","INFO:tensorflow:Step 2000 per-step time 0.970s\n","I0420 20:39:56.912402 139650086602624 model_lib_v2.py:707] Step 2000 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 0.54340684,\n"," 'Loss/localization_loss': 0.18090482,\n"," 'Loss/regularization_loss': 7.407708,\n"," 'Loss/total_loss': 8.13202,\n"," 'learning_rate': 0.03879385}\n","I0420 20:39:56.912731 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.54340684,\n"," 'Loss/localization_loss': 0.18090482,\n"," 'Loss/regularization_loss': 7.407708,\n"," 'Loss/total_loss': 8.13202,\n"," 'learning_rate': 0.03879385}\n","INFO:tensorflow:Step 2100 per-step time 0.996s\n","I0420 20:41:36.557844 139650086602624 model_lib_v2.py:707] Step 2100 per-step time 0.996s\n","INFO:tensorflow:{'Loss/classification_loss': 0.5935521,\n"," 'Loss/localization_loss': 0.18503812,\n"," 'Loss/regularization_loss': 7.1854715,\n"," 'Loss/total_loss': 7.9640617,\n"," 'learning_rate': 0.038543675}\n","I0420 20:41:36.558188 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.5935521,\n"," 'Loss/localization_loss': 0.18503812,\n"," 'Loss/regularization_loss': 7.1854715,\n"," 'Loss/total_loss': 7.9640617,\n"," 'learning_rate': 0.038543675}\n","INFO:tensorflow:Step 2200 per-step time 0.970s\n","I0420 20:43:13.559131 139650086602624 model_lib_v2.py:707] Step 2200 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 0.37150025,\n"," 'Loss/localization_loss': 0.09500347,\n"," 'Loss/regularization_loss': 6.970895,\n"," 'Loss/total_loss': 7.4373984,\n"," 'learning_rate': 0.03827091}\n","I0420 20:43:13.559478 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.37150025,\n"," 'Loss/localization_loss': 0.09500347,\n"," 'Loss/regularization_loss': 6.970895,\n"," 'Loss/total_loss': 7.4373984,\n"," 'learning_rate': 0.03827091}\n","INFO:tensorflow:Step 2300 per-step time 0.971s\n","I0420 20:44:50.643562 139650086602624 model_lib_v2.py:707] Step 2300 per-step time 0.971s\n","INFO:tensorflow:{'Loss/classification_loss': 0.6871223,\n"," 'Loss/localization_loss': 0.24779065,\n"," 'Loss/regularization_loss': 6.7645955,\n"," 'Loss/total_loss': 7.6995087,\n"," 'learning_rate': 0.03797588}\n","I0420 20:44:50.643861 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.6871223,\n"," 'Loss/localization_loss': 0.24779065,\n"," 'Loss/regularization_loss': 6.7645955,\n"," 'Loss/total_loss': 7.6995087,\n"," 'learning_rate': 0.03797588}\n","INFO:tensorflow:Step 2400 per-step time 0.970s\n","I0420 20:46:27.666436 139650086602624 model_lib_v2.py:707] Step 2400 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 0.6117021,\n"," 'Loss/localization_loss': 0.20138584,\n"," 'Loss/regularization_loss': 6.5662484,\n"," 'Loss/total_loss': 7.3793364,\n"," 'learning_rate': 0.037658952}\n","I0420 20:46:27.666740 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.6117021,\n"," 'Loss/localization_loss': 0.20138584,\n"," 'Loss/regularization_loss': 6.5662484,\n"," 'Loss/total_loss': 7.3793364,\n"," 'learning_rate': 0.037658952}\n","INFO:tensorflow:Step 2500 per-step time 0.969s\n","I0420 20:48:04.553704 139650086602624 model_lib_v2.py:707] Step 2500 per-step time 0.969s\n","INFO:tensorflow:{'Loss/classification_loss': 0.3793353,\n"," 'Loss/localization_loss': 0.17924675,\n"," 'Loss/regularization_loss': 6.375341,\n"," 'Loss/total_loss': 6.933923,\n"," 'learning_rate': 0.03732051}\n","I0420 20:48:04.553993 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.3793353,\n"," 'Loss/localization_loss': 0.17924675,\n"," 'Loss/regularization_loss': 6.375341,\n"," 'Loss/total_loss': 6.933923,\n"," 'learning_rate': 0.03732051}\n","INFO:tensorflow:Step 2600 per-step time 0.970s\n","I0420 20:49:41.600279 139650086602624 model_lib_v2.py:707] Step 2600 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 0.42732644,\n"," 'Loss/localization_loss': 0.12159192,\n"," 'Loss/regularization_loss': 6.191539,\n"," 'Loss/total_loss': 6.740457,\n"," 'learning_rate': 0.03696096}\n","I0420 20:49:41.600624 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.42732644,\n"," 'Loss/localization_loss': 0.12159192,\n"," 'Loss/regularization_loss': 6.191539,\n"," 'Loss/total_loss': 6.740457,\n"," 'learning_rate': 0.03696096}\n","INFO:tensorflow:Step 2700 per-step time 0.970s\n","I0420 20:51:18.594845 139650086602624 model_lib_v2.py:707] Step 2700 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 1.0846038,\n"," 'Loss/localization_loss': 0.3004952,\n"," 'Loss/regularization_loss': 6.067709,\n"," 'Loss/total_loss': 7.452808,\n"," 'learning_rate': 0.036580753}\n","I0420 20:51:18.595207 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 1.0846038,\n"," 'Loss/localization_loss': 0.3004952,\n"," 'Loss/regularization_loss': 6.067709,\n"," 'Loss/total_loss': 7.452808,\n"," 'learning_rate': 0.036580753}\n","INFO:tensorflow:Step 2800 per-step time 0.970s\n","I0420 20:52:55.612324 139650086602624 model_lib_v2.py:707] Step 2800 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 0.5285839,\n"," 'Loss/localization_loss': 0.23231003,\n"," 'Loss/regularization_loss': 5.949812,\n"," 'Loss/total_loss': 6.7107058,\n"," 'learning_rate': 0.03618034}\n","I0420 20:52:55.612687 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.5285839,\n"," 'Loss/localization_loss': 0.23231003,\n"," 'Loss/regularization_loss': 5.949812,\n"," 'Loss/total_loss': 6.7107058,\n"," 'learning_rate': 0.03618034}\n","INFO:tensorflow:Step 2900 per-step time 0.969s\n","I0420 20:54:32.537430 139650086602624 model_lib_v2.py:707] Step 2900 per-step time 0.969s\n","INFO:tensorflow:{'Loss/classification_loss': 0.6521186,\n"," 'Loss/localization_loss': 0.26795402,\n"," 'Loss/regularization_loss': 5.784391,\n"," 'Loss/total_loss': 6.7044635,\n"," 'learning_rate': 0.035760213}\n","I0420 20:54:32.537705 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.6521186,\n"," 'Loss/localization_loss': 0.26795402,\n"," 'Loss/regularization_loss': 5.784391,\n"," 'Loss/total_loss': 6.7044635,\n"," 'learning_rate': 0.035760213}\n","INFO:tensorflow:Step 3000 per-step time 0.970s\n","I0420 20:56:09.547356 139650086602624 model_lib_v2.py:707] Step 3000 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 0.58848256,\n"," 'Loss/localization_loss': 0.22404933,\n"," 'Loss/regularization_loss': 5.6254683,\n"," 'Loss/total_loss': 6.438,\n"," 'learning_rate': 0.035320885}\n","I0420 20:56:09.547643 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.58848256,\n"," 'Loss/localization_loss': 0.22404933,\n"," 'Loss/regularization_loss': 5.6254683,\n"," 'Loss/total_loss': 6.438,\n"," 'learning_rate': 0.035320885}\n","INFO:tensorflow:Step 3100 per-step time 0.983s\n","I0420 20:57:47.832822 139650086602624 model_lib_v2.py:707] Step 3100 per-step time 0.983s\n","INFO:tensorflow:{'Loss/classification_loss': 0.444451,\n"," 'Loss/localization_loss': 0.19078085,\n"," 'Loss/regularization_loss': 5.473055,\n"," 'Loss/total_loss': 6.108287,\n"," 'learning_rate': 0.034862895}\n","I0420 20:57:47.833100 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.444451,\n"," 'Loss/localization_loss': 0.19078085,\n"," 'Loss/regularization_loss': 5.473055,\n"," 'Loss/total_loss': 6.108287,\n"," 'learning_rate': 0.034862895}\n","INFO:tensorflow:Step 3200 per-step time 0.971s\n","I0420 20:59:24.882402 139650086602624 model_lib_v2.py:707] Step 3200 per-step time 0.971s\n","INFO:tensorflow:{'Loss/classification_loss': 0.40136042,\n"," 'Loss/localization_loss': 0.16853334,\n"," 'Loss/regularization_loss': 5.3264213,\n"," 'Loss/total_loss': 5.896315,\n"," 'learning_rate': 0.034386795}\n","I0420 20:59:24.882703 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.40136042,\n"," 'Loss/localization_loss': 0.16853334,\n"," 'Loss/regularization_loss': 5.3264213,\n"," 'Loss/total_loss': 5.896315,\n"," 'learning_rate': 0.034386795}\n","INFO:tensorflow:Step 3300 per-step time 0.970s\n","I0420 21:01:01.832462 139650086602624 model_lib_v2.py:707] Step 3300 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 0.42541716,\n"," 'Loss/localization_loss': 0.11922302,\n"," 'Loss/regularization_loss': 5.1855197,\n"," 'Loss/total_loss': 5.7301598,\n"," 'learning_rate': 0.033893168}\n","I0420 21:01:01.832722 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.42541716,\n"," 'Loss/localization_loss': 0.11922302,\n"," 'Loss/regularization_loss': 5.1855197,\n"," 'Loss/total_loss': 5.7301598,\n"," 'learning_rate': 0.033893168}\n","INFO:tensorflow:Step 3400 per-step time 0.968s\n","I0420 21:02:38.660517 139650086602624 model_lib_v2.py:707] Step 3400 per-step time 0.968s\n","INFO:tensorflow:{'Loss/classification_loss': 0.31431198,\n"," 'Loss/localization_loss': 0.108461946,\n"," 'Loss/regularization_loss': 5.0503693,\n"," 'Loss/total_loss': 5.473143,\n"," 'learning_rate': 0.03338261}\n","I0420 21:02:38.660795 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.31431198,\n"," 'Loss/localization_loss': 0.108461946,\n"," 'Loss/regularization_loss': 5.0503693,\n"," 'Loss/total_loss': 5.473143,\n"," 'learning_rate': 0.03338261}\n","INFO:tensorflow:Step 3500 per-step time 0.969s\n","I0420 21:04:15.611030 139650086602624 model_lib_v2.py:707] Step 3500 per-step time 0.969s\n","INFO:tensorflow:{'Loss/classification_loss': 0.32679433,\n"," 'Loss/localization_loss': 0.13561153,\n"," 'Loss/regularization_loss': 4.920775,\n"," 'Loss/total_loss': 5.3831806,\n"," 'learning_rate': 0.032855753}\n","I0420 21:04:15.611311 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.32679433,\n"," 'Loss/localization_loss': 0.13561153,\n"," 'Loss/regularization_loss': 4.920775,\n"," 'Loss/total_loss': 5.3831806,\n"," 'learning_rate': 0.032855753}\n","INFO:tensorflow:Step 3600 per-step time 0.971s\n","I0420 21:05:52.675202 139650086602624 model_lib_v2.py:707] Step 3600 per-step time 0.971s\n","INFO:tensorflow:{'Loss/classification_loss': 0.34400207,\n"," 'Loss/localization_loss': 0.11267738,\n"," 'Loss/regularization_loss': 4.79631,\n"," 'Loss/total_loss': 5.2529893,\n"," 'learning_rate': 0.032313228}\n","I0420 21:05:52.675531 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.34400207,\n"," 'Loss/localization_loss': 0.11267738,\n"," 'Loss/regularization_loss': 4.79631,\n"," 'Loss/total_loss': 5.2529893,\n"," 'learning_rate': 0.032313228}\n","INFO:tensorflow:Step 3700 per-step time 0.969s\n","I0420 21:07:29.600003 139650086602624 model_lib_v2.py:707] Step 3700 per-step time 0.969s\n","INFO:tensorflow:{'Loss/classification_loss': 0.23568922,\n"," 'Loss/localization_loss': 0.07630237,\n"," 'Loss/regularization_loss': 4.677008,\n"," 'Loss/total_loss': 4.989,\n"," 'learning_rate': 0.031755704}\n","I0420 21:07:29.600306 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.23568922,\n"," 'Loss/localization_loss': 0.07630237,\n"," 'Loss/regularization_loss': 4.677008,\n"," 'Loss/total_loss': 4.989,\n"," 'learning_rate': 0.031755704}\n","INFO:tensorflow:Step 3800 per-step time 0.969s\n","I0420 21:09:06.454915 139650086602624 model_lib_v2.py:707] Step 3800 per-step time 0.969s\n","INFO:tensorflow:{'Loss/classification_loss': 0.25531,\n"," 'Loss/localization_loss': 0.080706656,\n"," 'Loss/regularization_loss': 4.5627046,\n"," 'Loss/total_loss': 4.898721,\n"," 'learning_rate': 0.031183857}\n","I0420 21:09:06.455199 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.25531,\n"," 'Loss/localization_loss': 0.080706656,\n"," 'Loss/regularization_loss': 4.5627046,\n"," 'Loss/total_loss': 4.898721,\n"," 'learning_rate': 0.031183857}\n","INFO:tensorflow:Step 3900 per-step time 0.969s\n","I0420 21:10:43.381680 139650086602624 model_lib_v2.py:707] Step 3900 per-step time 0.969s\n","INFO:tensorflow:{'Loss/classification_loss': 0.21091469,\n"," 'Loss/localization_loss': 0.068797536,\n"," 'Loss/regularization_loss': 4.453234,\n"," 'Loss/total_loss': 4.7329464,\n"," 'learning_rate': 0.030598382}\n","I0420 21:10:43.381956 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.21091469,\n"," 'Loss/localization_loss': 0.068797536,\n"," 'Loss/regularization_loss': 4.453234,\n"," 'Loss/total_loss': 4.7329464,\n"," 'learning_rate': 0.030598382}\n","INFO:tensorflow:Step 4000 per-step time 0.969s\n","I0420 21:12:20.299774 139650086602624 model_lib_v2.py:707] Step 4000 per-step time 0.969s\n","INFO:tensorflow:{'Loss/classification_loss': 0.24527752,\n"," 'Loss/localization_loss': 0.1197675,\n"," 'Loss/regularization_loss': 4.3483343,\n"," 'Loss/total_loss': 4.7133794,\n"," 'learning_rate': 0.03}\n","I0420 21:12:20.300053 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.24527752,\n"," 'Loss/localization_loss': 0.1197675,\n"," 'Loss/regularization_loss': 4.3483343,\n"," 'Loss/total_loss': 4.7133794,\n"," 'learning_rate': 0.03}\n","INFO:tensorflow:Step 4100 per-step time 0.986s\n","I0420 21:13:58.852481 139650086602624 model_lib_v2.py:707] Step 4100 per-step time 0.986s\n","INFO:tensorflow:{'Loss/classification_loss': 0.29288036,\n"," 'Loss/localization_loss': 0.105493225,\n"," 'Loss/regularization_loss': 4.2481565,\n"," 'Loss/total_loss': 4.64653,\n"," 'learning_rate': 0.029389428}\n","I0420 21:13:58.852787 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.29288036,\n"," 'Loss/localization_loss': 0.105493225,\n"," 'Loss/regularization_loss': 4.2481565,\n"," 'Loss/total_loss': 4.64653,\n"," 'learning_rate': 0.029389428}\n","INFO:tensorflow:Step 4200 per-step time 0.970s\n","I0420 21:15:35.838158 139650086602624 model_lib_v2.py:707] Step 4200 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 0.3218993,\n"," 'Loss/localization_loss': 0.088287435,\n"," 'Loss/regularization_loss': 4.1524615,\n"," 'Loss/total_loss': 4.5626483,\n"," 'learning_rate': 0.028767424}\n","I0420 21:15:35.838463 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.3218993,\n"," 'Loss/localization_loss': 0.088287435,\n"," 'Loss/regularization_loss': 4.1524615,\n"," 'Loss/total_loss': 4.5626483,\n"," 'learning_rate': 0.028767424}\n","INFO:tensorflow:Step 4300 per-step time 0.969s\n","I0420 21:17:12.783149 139650086602624 model_lib_v2.py:707] Step 4300 per-step time 0.969s\n","INFO:tensorflow:{'Loss/classification_loss': 0.20257218,\n"," 'Loss/localization_loss': 0.07316673,\n"," 'Loss/regularization_loss': 4.0606833,\n"," 'Loss/total_loss': 4.336422,\n"," 'learning_rate': 0.028134732}\n","I0420 21:17:12.783424 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.20257218,\n"," 'Loss/localization_loss': 0.07316673,\n"," 'Loss/regularization_loss': 4.0606833,\n"," 'Loss/total_loss': 4.336422,\n"," 'learning_rate': 0.028134732}\n","INFO:tensorflow:Step 4400 per-step time 0.969s\n","I0420 21:18:49.656499 139650086602624 model_lib_v2.py:707] Step 4400 per-step time 0.969s\n","INFO:tensorflow:{'Loss/classification_loss': 0.23149814,\n"," 'Loss/localization_loss': 0.09865421,\n"," 'Loss/regularization_loss': 3.9728246,\n"," 'Loss/total_loss': 4.302977,\n"," 'learning_rate': 0.027492132}\n","I0420 21:18:49.656750 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.23149814,\n"," 'Loss/localization_loss': 0.09865421,\n"," 'Loss/regularization_loss': 3.9728246,\n"," 'Loss/total_loss': 4.302977,\n"," 'learning_rate': 0.027492132}\n","INFO:tensorflow:Step 4500 per-step time 0.969s\n","I0420 21:20:26.585900 139650086602624 model_lib_v2.py:707] Step 4500 per-step time 0.969s\n","INFO:tensorflow:{'Loss/classification_loss': 0.24745339,\n"," 'Loss/localization_loss': 0.07524823,\n"," 'Loss/regularization_loss': 3.8888023,\n"," 'Loss/total_loss': 4.211504,\n"," 'learning_rate': 0.026840402}\n","I0420 21:20:26.586217 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.24745339,\n"," 'Loss/localization_loss': 0.07524823,\n"," 'Loss/regularization_loss': 3.8888023,\n"," 'Loss/total_loss': 4.211504,\n"," 'learning_rate': 0.026840402}\n","INFO:tensorflow:Step 4600 per-step time 0.969s\n","I0420 21:22:03.484433 139650086602624 model_lib_v2.py:707] Step 4600 per-step time 0.969s\n","INFO:tensorflow:{'Loss/classification_loss': 0.20467491,\n"," 'Loss/localization_loss': 0.06502115,\n"," 'Loss/regularization_loss': 3.8086936,\n"," 'Loss/total_loss': 4.0783896,\n"," 'learning_rate': 0.026180338}\n","I0420 21:22:03.484710 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.20467491,\n"," 'Loss/localization_loss': 0.06502115,\n"," 'Loss/regularization_loss': 3.8086936,\n"," 'Loss/total_loss': 4.0783896,\n"," 'learning_rate': 0.026180338}\n","INFO:tensorflow:Step 4700 per-step time 0.970s\n","I0420 21:23:40.526029 139650086602624 model_lib_v2.py:707] Step 4700 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 0.18262626,\n"," 'Loss/localization_loss': 0.056179628,\n"," 'Loss/regularization_loss': 3.7323518,\n"," 'Loss/total_loss': 3.9711576,\n"," 'learning_rate': 0.025512746}\n","I0420 21:23:40.526362 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.18262626,\n"," 'Loss/localization_loss': 0.056179628,\n"," 'Loss/regularization_loss': 3.7323518,\n"," 'Loss/total_loss': 3.9711576,\n"," 'learning_rate': 0.025512746}\n","INFO:tensorflow:Step 4800 per-step time 0.969s\n","I0420 21:25:17.436960 139650086602624 model_lib_v2.py:707] Step 4800 per-step time 0.969s\n","INFO:tensorflow:{'Loss/classification_loss': 0.21901485,\n"," 'Loss/localization_loss': 0.07972397,\n"," 'Loss/regularization_loss': 3.659105,\n"," 'Loss/total_loss': 3.9578438,\n"," 'learning_rate': 0.024838435}\n","I0420 21:25:17.437248 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.21901485,\n"," 'Loss/localization_loss': 0.07972397,\n"," 'Loss/regularization_loss': 3.659105,\n"," 'Loss/total_loss': 3.9578438,\n"," 'learning_rate': 0.024838435}\n","INFO:tensorflow:Step 4900 per-step time 0.970s\n","I0420 21:26:54.396736 139650086602624 model_lib_v2.py:707] Step 4900 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 0.20099723,\n"," 'Loss/localization_loss': 0.059039924,\n"," 'Loss/regularization_loss': 3.5892034,\n"," 'Loss/total_loss': 3.8492405,\n"," 'learning_rate': 0.024158232}\n","I0420 21:26:54.397041 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.20099723,\n"," 'Loss/localization_loss': 0.059039924,\n"," 'Loss/regularization_loss': 3.5892034,\n"," 'Loss/total_loss': 3.8492405,\n"," 'learning_rate': 0.024158232}\n","INFO:tensorflow:Step 5000 per-step time 0.970s\n","I0420 21:28:31.392129 139650086602624 model_lib_v2.py:707] Step 5000 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 0.21871795,\n"," 'Loss/localization_loss': 0.05135991,\n"," 'Loss/regularization_loss': 3.522589,\n"," 'Loss/total_loss': 3.792667,\n"," 'learning_rate': 0.023472961}\n","I0420 21:28:31.392406 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.21871795,\n"," 'Loss/localization_loss': 0.05135991,\n"," 'Loss/regularization_loss': 3.522589,\n"," 'Loss/total_loss': 3.792667,\n"," 'learning_rate': 0.023472961}\n","INFO:tensorflow:Step 5100 per-step time 0.984s\n","I0420 21:30:09.753777 139650086602624 model_lib_v2.py:707] Step 5100 per-step time 0.984s\n","INFO:tensorflow:{'Loss/classification_loss': 0.32640246,\n"," 'Loss/localization_loss': 0.11624901,\n"," 'Loss/regularization_loss': 3.4593136,\n"," 'Loss/total_loss': 3.9019651,\n"," 'learning_rate': 0.022783462}\n","I0420 21:30:09.754051 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.32640246,\n"," 'Loss/localization_loss': 0.11624901,\n"," 'Loss/regularization_loss': 3.4593136,\n"," 'Loss/total_loss': 3.9019651,\n"," 'learning_rate': 0.022783462}\n","INFO:tensorflow:Step 5200 per-step time 0.970s\n","I0420 21:31:46.744820 139650086602624 model_lib_v2.py:707] Step 5200 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 0.19761346,\n"," 'Loss/localization_loss': 0.05805218,\n"," 'Loss/regularization_loss': 3.399019,\n"," 'Loss/total_loss': 3.6546845,\n"," 'learning_rate': 0.022090567}\n","I0420 21:31:46.745077 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.19761346,\n"," 'Loss/localization_loss': 0.05805218,\n"," 'Loss/regularization_loss': 3.399019,\n"," 'Loss/total_loss': 3.6546845,\n"," 'learning_rate': 0.022090567}\n","INFO:tensorflow:Step 5300 per-step time 0.970s\n","I0420 21:33:23.708280 139650086602624 model_lib_v2.py:707] Step 5300 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 0.3125155,\n"," 'Loss/localization_loss': 0.07766748,\n"," 'Loss/regularization_loss': 3.341421,\n"," 'Loss/total_loss': 3.7316039,\n"," 'learning_rate': 0.021395128}\n","I0420 21:33:23.708556 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.3125155,\n"," 'Loss/localization_loss': 0.07766748,\n"," 'Loss/regularization_loss': 3.341421,\n"," 'Loss/total_loss': 3.7316039,\n"," 'learning_rate': 0.021395128}\n","INFO:tensorflow:Step 5400 per-step time 0.968s\n","I0420 21:35:00.541886 139650086602624 model_lib_v2.py:707] Step 5400 per-step time 0.968s\n","INFO:tensorflow:{'Loss/classification_loss': 0.16310644,\n"," 'Loss/localization_loss': 0.045790616,\n"," 'Loss/regularization_loss': 3.2866604,\n"," 'Loss/total_loss': 3.4955575,\n"," 'learning_rate': 0.020697989}\n","I0420 21:35:00.542203 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.16310644,\n"," 'Loss/localization_loss': 0.045790616,\n"," 'Loss/regularization_loss': 3.2866604,\n"," 'Loss/total_loss': 3.4955575,\n"," 'learning_rate': 0.020697989}\n","INFO:tensorflow:Step 5500 per-step time 0.970s\n","I0420 21:36:37.550069 139650086602624 model_lib_v2.py:707] Step 5500 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 0.2264293,\n"," 'Loss/localization_loss': 0.06701447,\n"," 'Loss/regularization_loss': 3.2344174,\n"," 'Loss/total_loss': 3.527861,\n"," 'learning_rate': 0.019999998}\n","I0420 21:36:37.550361 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.2264293,\n"," 'Loss/localization_loss': 0.06701447,\n"," 'Loss/regularization_loss': 3.2344174,\n"," 'Loss/total_loss': 3.527861,\n"," 'learning_rate': 0.019999998}\n","INFO:tensorflow:Step 5600 per-step time 0.969s\n","I0420 21:38:14.469932 139650086602624 model_lib_v2.py:707] Step 5600 per-step time 0.969s\n","INFO:tensorflow:{'Loss/classification_loss': 0.22167914,\n"," 'Loss/localization_loss': 0.11636009,\n"," 'Loss/regularization_loss': 3.1847186,\n"," 'Loss/total_loss': 3.5227578,\n"," 'learning_rate': 0.01930201}\n","I0420 21:38:14.470214 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.22167914,\n"," 'Loss/localization_loss': 0.11636009,\n"," 'Loss/regularization_loss': 3.1847186,\n"," 'Loss/total_loss': 3.5227578,\n"," 'learning_rate': 0.01930201}\n","INFO:tensorflow:Step 5700 per-step time 0.969s\n","I0420 21:39:51.416250 139650086602624 model_lib_v2.py:707] Step 5700 per-step time 0.969s\n","INFO:tensorflow:{'Loss/classification_loss': 0.21999468,\n"," 'Loss/localization_loss': 0.049655095,\n"," 'Loss/regularization_loss': 3.137479,\n"," 'Loss/total_loss': 3.4071288,\n"," 'learning_rate': 0.018604867}\n","I0420 21:39:51.416615 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.21999468,\n"," 'Loss/localization_loss': 0.049655095,\n"," 'Loss/regularization_loss': 3.137479,\n"," 'Loss/total_loss': 3.4071288,\n"," 'learning_rate': 0.018604867}\n","INFO:tensorflow:Step 5800 per-step time 0.969s\n","I0420 21:41:28.319903 139650086602624 model_lib_v2.py:707] Step 5800 per-step time 0.969s\n","INFO:tensorflow:{'Loss/classification_loss': 0.22759725,\n"," 'Loss/localization_loss': 0.105516255,\n"," 'Loss/regularization_loss': 3.092651,\n"," 'Loss/total_loss': 3.4257643,\n"," 'learning_rate': 0.01790943}\n","I0420 21:41:28.320157 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.22759725,\n"," 'Loss/localization_loss': 0.105516255,\n"," 'Loss/regularization_loss': 3.092651,\n"," 'Loss/total_loss': 3.4257643,\n"," 'learning_rate': 0.01790943}\n","INFO:tensorflow:Step 5900 per-step time 0.970s\n","I0420 21:43:05.293996 139650086602624 model_lib_v2.py:707] Step 5900 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 0.23212811,\n"," 'Loss/localization_loss': 0.052168846,\n"," 'Loss/regularization_loss': 3.0502336,\n"," 'Loss/total_loss': 3.3345306,\n"," 'learning_rate': 0.017216535}\n","I0420 21:43:05.294289 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.23212811,\n"," 'Loss/localization_loss': 0.052168846,\n"," 'Loss/regularization_loss': 3.0502336,\n"," 'Loss/total_loss': 3.3345306,\n"," 'learning_rate': 0.017216535}\n","INFO:tensorflow:Step 6000 per-step time 0.970s\n","I0420 21:44:42.327881 139650086602624 model_lib_v2.py:707] Step 6000 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 0.20973171,\n"," 'Loss/localization_loss': 0.05826911,\n"," 'Loss/regularization_loss': 3.009949,\n"," 'Loss/total_loss': 3.2779498,\n"," 'learning_rate': 0.016527036}\n","I0420 21:44:42.328151 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.20973171,\n"," 'Loss/localization_loss': 0.05826911,\n"," 'Loss/regularization_loss': 3.009949,\n"," 'Loss/total_loss': 3.2779498,\n"," 'learning_rate': 0.016527036}\n","INFO:tensorflow:Step 6100 per-step time 0.984s\n","I0420 21:46:20.735993 139650086602624 model_lib_v2.py:707] Step 6100 per-step time 0.984s\n","INFO:tensorflow:{'Loss/classification_loss': 0.26470187,\n"," 'Loss/localization_loss': 0.060613047,\n"," 'Loss/regularization_loss': 2.9717772,\n"," 'Loss/total_loss': 3.2970922,\n"," 'learning_rate': 0.015841765}\n","I0420 21:46:20.736266 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.26470187,\n"," 'Loss/localization_loss': 0.060613047,\n"," 'Loss/regularization_loss': 2.9717772,\n"," 'Loss/total_loss': 3.2970922,\n"," 'learning_rate': 0.015841765}\n","INFO:tensorflow:Step 6200 per-step time 0.969s\n","I0420 21:47:57.638991 139650086602624 model_lib_v2.py:707] Step 6200 per-step time 0.969s\n","INFO:tensorflow:{'Loss/classification_loss': 0.26672,\n"," 'Loss/localization_loss': 0.08420173,\n"," 'Loss/regularization_loss': 2.9355934,\n"," 'Loss/total_loss': 3.286515,\n"," 'learning_rate': 0.015161559}\n","I0420 21:47:57.639250 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.26672,\n"," 'Loss/localization_loss': 0.08420173,\n"," 'Loss/regularization_loss': 2.9355934,\n"," 'Loss/total_loss': 3.286515,\n"," 'learning_rate': 0.015161559}\n","INFO:tensorflow:Step 6300 per-step time 0.971s\n","I0420 21:49:34.688823 139650086602624 model_lib_v2.py:707] Step 6300 per-step time 0.971s\n","INFO:tensorflow:{'Loss/classification_loss': 0.15081997,\n"," 'Loss/localization_loss': 0.04299159,\n"," 'Loss/regularization_loss': 2.9013782,\n"," 'Loss/total_loss': 3.0951898,\n"," 'learning_rate': 0.014487252}\n","I0420 21:49:34.689089 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.15081997,\n"," 'Loss/localization_loss': 0.04299159,\n"," 'Loss/regularization_loss': 2.9013782,\n"," 'Loss/total_loss': 3.0951898,\n"," 'learning_rate': 0.014487252}\n","INFO:tensorflow:Step 6400 per-step time 0.970s\n","I0420 21:51:11.710651 139650086602624 model_lib_v2.py:707] Step 6400 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 0.19165915,\n"," 'Loss/localization_loss': 0.047030002,\n"," 'Loss/regularization_loss': 2.869104,\n"," 'Loss/total_loss': 3.107793,\n"," 'learning_rate': 0.013819656}\n","I0420 21:51:11.710964 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.19165915,\n"," 'Loss/localization_loss': 0.047030002,\n"," 'Loss/regularization_loss': 2.869104,\n"," 'Loss/total_loss': 3.107793,\n"," 'learning_rate': 0.013819656}\n","INFO:tensorflow:Step 6500 per-step time 0.970s\n","I0420 21:52:48.706937 139650086602624 model_lib_v2.py:707] Step 6500 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 0.2573775,\n"," 'Loss/localization_loss': 0.0631718,\n"," 'Loss/regularization_loss': 2.8387582,\n"," 'Loss/total_loss': 3.1593075,\n"," 'learning_rate': 0.013159598}\n","I0420 21:52:48.707239 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.2573775,\n"," 'Loss/localization_loss': 0.0631718,\n"," 'Loss/regularization_loss': 2.8387582,\n"," 'Loss/total_loss': 3.1593075,\n"," 'learning_rate': 0.013159598}\n","INFO:tensorflow:Step 6600 per-step time 0.970s\n","I0420 21:54:25.740339 139650086602624 model_lib_v2.py:707] Step 6600 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 0.18000554,\n"," 'Loss/localization_loss': 0.045067884,\n"," 'Loss/regularization_loss': 2.810178,\n"," 'Loss/total_loss': 3.0352514,\n"," 'learning_rate': 0.012507865}\n","I0420 21:54:25.740618 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.18000554,\n"," 'Loss/localization_loss': 0.045067884,\n"," 'Loss/regularization_loss': 2.810178,\n"," 'Loss/total_loss': 3.0352514,\n"," 'learning_rate': 0.012507865}\n","INFO:tensorflow:Step 6700 per-step time 0.970s\n","I0420 21:56:02.750048 139650086602624 model_lib_v2.py:707] Step 6700 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 0.19784686,\n"," 'Loss/localization_loss': 0.0695754,\n"," 'Loss/regularization_loss': 2.7831788,\n"," 'Loss/total_loss': 3.050601,\n"," 'learning_rate': 0.011865267}\n","I0420 21:56:02.750341 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.19784686,\n"," 'Loss/localization_loss': 0.0695754,\n"," 'Loss/regularization_loss': 2.7831788,\n"," 'Loss/total_loss': 3.050601,\n"," 'learning_rate': 0.011865267}\n","INFO:tensorflow:Step 6800 per-step time 0.971s\n","I0420 21:57:39.820892 139650086602624 model_lib_v2.py:707] Step 6800 per-step time 0.971s\n","INFO:tensorflow:{'Loss/classification_loss': 0.1533923,\n"," 'Loss/localization_loss': 0.04285004,\n"," 'Loss/regularization_loss': 2.757758,\n"," 'Loss/total_loss': 2.9540002,\n"," 'learning_rate': 0.011232574}\n","I0420 21:57:39.821163 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.1533923,\n"," 'Loss/localization_loss': 0.04285004,\n"," 'Loss/regularization_loss': 2.757758,\n"," 'Loss/total_loss': 2.9540002,\n"," 'learning_rate': 0.011232574}\n","INFO:tensorflow:Step 6900 per-step time 0.970s\n","I0420 21:59:16.839973 139650086602624 model_lib_v2.py:707] Step 6900 per-step time 0.970s\n","INFO:tensorflow:{'Loss/classification_loss': 0.12280143,\n"," 'Loss/localization_loss': 0.030011293,\n"," 'Loss/regularization_loss': 2.7339597,\n"," 'Loss/total_loss': 2.8867724,\n"," 'learning_rate': 0.010610568}\n","I0420 21:59:16.840238 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.12280143,\n"," 'Loss/localization_loss': 0.030011293,\n"," 'Loss/regularization_loss': 2.7339597,\n"," 'Loss/total_loss': 2.8867724,\n"," 'learning_rate': 0.010610568}\n","INFO:tensorflow:Step 7000 per-step time 0.971s\n","I0420 22:00:53.917727 139650086602624 model_lib_v2.py:707] Step 7000 per-step time 0.971s\n","INFO:tensorflow:{'Loss/classification_loss': 0.27594104,\n"," 'Loss/localization_loss': 0.10140471,\n"," 'Loss/regularization_loss': 2.711705,\n"," 'Loss/total_loss': 3.0890508,\n"," 'learning_rate': 0.009999999}\n","I0420 22:00:53.917998 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.27594104,\n"," 'Loss/localization_loss': 0.10140471,\n"," 'Loss/regularization_loss': 2.711705,\n"," 'Loss/total_loss': 3.0890508,\n"," 'learning_rate': 0.009999999}\n","INFO:tensorflow:Step 7100 per-step time 0.991s\n","I0420 22:02:33.003572 139650086602624 model_lib_v2.py:707] Step 7100 per-step time 0.991s\n","INFO:tensorflow:{'Loss/classification_loss': 0.22080241,\n"," 'Loss/localization_loss': 0.05923099,\n"," 'Loss/regularization_loss': 2.690852,\n"," 'Loss/total_loss': 2.9708853,\n"," 'learning_rate': 0.009401617}\n","I0420 22:02:33.003845 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.22080241,\n"," 'Loss/localization_loss': 0.05923099,\n"," 'Loss/regularization_loss': 2.690852,\n"," 'Loss/total_loss': 2.9708853,\n"," 'learning_rate': 0.009401617}\n","INFO:tensorflow:Step 7200 per-step time 0.959s\n","I0420 22:04:08.873723 139650086602624 model_lib_v2.py:707] Step 7200 per-step time 0.959s\n","INFO:tensorflow:{'Loss/classification_loss': 0.2060549,\n"," 'Loss/localization_loss': 0.04467611,\n"," 'Loss/regularization_loss': 2.6714644,\n"," 'Loss/total_loss': 2.9221954,\n"," 'learning_rate': 0.00881614}\n","I0420 22:04:08.873990 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.2060549,\n"," 'Loss/localization_loss': 0.04467611,\n"," 'Loss/regularization_loss': 2.6714644,\n"," 'Loss/total_loss': 2.9221954,\n"," 'learning_rate': 0.00881614}\n","INFO:tensorflow:Step 7300 per-step time 0.959s\n","I0420 22:05:44.744596 139650086602624 model_lib_v2.py:707] Step 7300 per-step time 0.959s\n","INFO:tensorflow:{'Loss/classification_loss': 0.15313864,\n"," 'Loss/localization_loss': 0.035366613,\n"," 'Loss/regularization_loss': 2.6533937,\n"," 'Loss/total_loss': 2.841899,\n"," 'learning_rate': 0.008244291}\n","I0420 22:05:44.744878 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.15313864,\n"," 'Loss/localization_loss': 0.035366613,\n"," 'Loss/regularization_loss': 2.6533937,\n"," 'Loss/total_loss': 2.841899,\n"," 'learning_rate': 0.008244291}\n","INFO:tensorflow:Step 7400 per-step time 0.958s\n","I0420 22:07:20.586784 139650086602624 model_lib_v2.py:707] Step 7400 per-step time 0.958s\n","INFO:tensorflow:{'Loss/classification_loss': 0.11273894,\n"," 'Loss/localization_loss': 0.060953017,\n"," 'Loss/regularization_loss': 2.6366167,\n"," 'Loss/total_loss': 2.8103087,\n"," 'learning_rate': 0.0076867696}\n","I0420 22:07:20.587054 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.11273894,\n"," 'Loss/localization_loss': 0.060953017,\n"," 'Loss/regularization_loss': 2.6366167,\n"," 'Loss/total_loss': 2.8103087,\n"," 'learning_rate': 0.0076867696}\n","INFO:tensorflow:Step 7500 per-step time 0.960s\n","I0420 22:08:56.562522 139650086602624 model_lib_v2.py:707] Step 7500 per-step time 0.960s\n","INFO:tensorflow:{'Loss/classification_loss': 0.122322395,\n"," 'Loss/localization_loss': 0.0415704,\n"," 'Loss/regularization_loss': 2.6210887,\n"," 'Loss/total_loss': 2.7849815,\n"," 'learning_rate': 0.007144247}\n","I0420 22:08:56.562845 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.122322395,\n"," 'Loss/localization_loss': 0.0415704,\n"," 'Loss/regularization_loss': 2.6210887,\n"," 'Loss/total_loss': 2.7849815,\n"," 'learning_rate': 0.007144247}\n","INFO:tensorflow:Step 7600 per-step time 0.960s\n","I0420 22:10:32.535944 139650086602624 model_lib_v2.py:707] Step 7600 per-step time 0.960s\n","INFO:tensorflow:{'Loss/classification_loss': 0.23954572,\n"," 'Loss/localization_loss': 0.06547106,\n"," 'Loss/regularization_loss': 2.606792,\n"," 'Loss/total_loss': 2.9118087,\n"," 'learning_rate': 0.0066173864}\n","I0420 22:10:32.536236 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.23954572,\n"," 'Loss/localization_loss': 0.06547106,\n"," 'Loss/regularization_loss': 2.606792,\n"," 'Loss/total_loss': 2.9118087,\n"," 'learning_rate': 0.0066173864}\n","INFO:tensorflow:Step 7700 per-step time 0.959s\n","I0420 22:12:08.406292 139650086602624 model_lib_v2.py:707] Step 7700 per-step time 0.959s\n","INFO:tensorflow:{'Loss/classification_loss': 0.16766024,\n"," 'Loss/localization_loss': 0.037305854,\n"," 'Loss/regularization_loss': 2.5936022,\n"," 'Loss/total_loss': 2.7985682,\n"," 'learning_rate': 0.0061068307}\n","I0420 22:12:08.406603 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.16766024,\n"," 'Loss/localization_loss': 0.037305854,\n"," 'Loss/regularization_loss': 2.5936022,\n"," 'Loss/total_loss': 2.7985682,\n"," 'learning_rate': 0.0061068307}\n","INFO:tensorflow:Step 7800 per-step time 0.959s\n","I0420 22:13:44.329939 139650086602624 model_lib_v2.py:707] Step 7800 per-step time 0.959s\n","INFO:tensorflow:{'Loss/classification_loss': 0.12996776,\n"," 'Loss/localization_loss': 0.047142852,\n"," 'Loss/regularization_loss': 2.5814865,\n"," 'Loss/total_loss': 2.7585971,\n"," 'learning_rate': 0.0056132055}\n","I0420 22:13:44.330199 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.12996776,\n"," 'Loss/localization_loss': 0.047142852,\n"," 'Loss/regularization_loss': 2.5814865,\n"," 'Loss/total_loss': 2.7585971,\n"," 'learning_rate': 0.0056132055}\n","INFO:tensorflow:Step 7900 per-step time 0.959s\n","I0420 22:15:20.204699 139650086602624 model_lib_v2.py:707] Step 7900 per-step time 0.959s\n","INFO:tensorflow:{'Loss/classification_loss': 0.15601438,\n"," 'Loss/localization_loss': 0.057085745,\n"," 'Loss/regularization_loss': 2.5704222,\n"," 'Loss/total_loss': 2.7835224,\n"," 'learning_rate': 0.0051371}\n","I0420 22:15:20.204968 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.15601438,\n"," 'Loss/localization_loss': 0.057085745,\n"," 'Loss/regularization_loss': 2.5704222,\n"," 'Loss/total_loss': 2.7835224,\n"," 'learning_rate': 0.0051371}\n","INFO:tensorflow:Step 8000 per-step time 0.958s\n","I0420 22:16:56.018401 139650086602624 model_lib_v2.py:707] Step 8000 per-step time 0.958s\n","INFO:tensorflow:{'Loss/classification_loss': 0.15162021,\n"," 'Loss/localization_loss': 0.04174964,\n"," 'Loss/regularization_loss': 2.5603447,\n"," 'Loss/total_loss': 2.7537146,\n"," 'learning_rate': 0.0046791113}\n","I0420 22:16:56.018680 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.15162021,\n"," 'Loss/localization_loss': 0.04174964,\n"," 'Loss/regularization_loss': 2.5603447,\n"," 'Loss/total_loss': 2.7537146,\n"," 'learning_rate': 0.0046791113}\n","INFO:tensorflow:Step 8100 per-step time 0.974s\n","I0420 22:18:33.398096 139650086602624 model_lib_v2.py:707] Step 8100 per-step time 0.974s\n","INFO:tensorflow:{'Loss/classification_loss': 0.27144894,\n"," 'Loss/localization_loss': 0.0713377,\n"," 'Loss/regularization_loss': 2.551205,\n"," 'Loss/total_loss': 2.8939915,\n"," 'learning_rate': 0.0042397846}\n","I0420 22:18:33.398400 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.27144894,\n"," 'Loss/localization_loss': 0.0713377,\n"," 'Loss/regularization_loss': 2.551205,\n"," 'Loss/total_loss': 2.8939915,\n"," 'learning_rate': 0.0042397846}\n","INFO:tensorflow:Step 8200 per-step time 0.958s\n","I0420 22:20:09.169311 139650086602624 model_lib_v2.py:707] Step 8200 per-step time 0.958s\n","INFO:tensorflow:{'Loss/classification_loss': 0.10811832,\n"," 'Loss/localization_loss': 0.032186866,\n"," 'Loss/regularization_loss': 2.542971,\n"," 'Loss/total_loss': 2.6832762,\n"," 'learning_rate': 0.0038196587}\n","I0420 22:20:09.169617 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.10811832,\n"," 'Loss/localization_loss': 0.032186866,\n"," 'Loss/regularization_loss': 2.542971,\n"," 'Loss/total_loss': 2.6832762,\n"," 'learning_rate': 0.0038196587}\n","INFO:tensorflow:Step 8300 per-step time 0.958s\n","I0420 22:21:44.976661 139650086602624 model_lib_v2.py:707] Step 8300 per-step time 0.958s\n","INFO:tensorflow:{'Loss/classification_loss': 0.113580756,\n"," 'Loss/localization_loss': 0.0396637,\n"," 'Loss/regularization_loss': 2.535592,\n"," 'Loss/total_loss': 2.6888366,\n"," 'learning_rate': 0.0034192465}\n","I0420 22:21:44.976927 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.113580756,\n"," 'Loss/localization_loss': 0.0396637,\n"," 'Loss/regularization_loss': 2.535592,\n"," 'Loss/total_loss': 2.6888366,\n"," 'learning_rate': 0.0034192465}\n","INFO:tensorflow:Step 8400 per-step time 0.958s\n","I0420 22:23:20.826489 139650086602624 model_lib_v2.py:707] Step 8400 per-step time 0.958s\n","INFO:tensorflow:{'Loss/classification_loss': 0.1179084,\n"," 'Loss/localization_loss': 0.05783079,\n"," 'Loss/regularization_loss': 2.5290174,\n"," 'Loss/total_loss': 2.7047567,\n"," 'learning_rate': 0.0030390369}\n","I0420 22:23:20.826795 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.1179084,\n"," 'Loss/localization_loss': 0.05783079,\n"," 'Loss/regularization_loss': 2.5290174,\n"," 'Loss/total_loss': 2.7047567,\n"," 'learning_rate': 0.0030390369}\n","INFO:tensorflow:Step 8500 per-step time 0.958s\n","I0420 22:24:56.666537 139650086602624 model_lib_v2.py:707] Step 8500 per-step time 0.958s\n","INFO:tensorflow:{'Loss/classification_loss': 0.12265913,\n"," 'Loss/localization_loss': 0.04526117,\n"," 'Loss/regularization_loss': 2.523194,\n"," 'Loss/total_loss': 2.6911144,\n"," 'learning_rate': 0.002679492}\n","I0420 22:24:56.666826 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.12265913,\n"," 'Loss/localization_loss': 0.04526117,\n"," 'Loss/regularization_loss': 2.523194,\n"," 'Loss/total_loss': 2.6911144,\n"," 'learning_rate': 0.002679492}\n","INFO:tensorflow:Step 8600 per-step time 0.960s\n","I0420 22:26:32.682721 139650086602624 model_lib_v2.py:707] Step 8600 per-step time 0.960s\n","INFO:tensorflow:{'Loss/classification_loss': 0.128746,\n"," 'Loss/localization_loss': 0.02584838,\n"," 'Loss/regularization_loss': 2.5180974,\n"," 'Loss/total_loss': 2.6726918,\n"," 'learning_rate': 0.002341045}\n","I0420 22:26:32.682985 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.128746,\n"," 'Loss/localization_loss': 0.02584838,\n"," 'Loss/regularization_loss': 2.5180974,\n"," 'Loss/total_loss': 2.6726918,\n"," 'learning_rate': 0.002341045}\n","INFO:tensorflow:Step 8700 per-step time 0.959s\n","I0420 22:28:08.540998 139650086602624 model_lib_v2.py:707] Step 8700 per-step time 0.959s\n","INFO:tensorflow:{'Loss/classification_loss': 0.16938958,\n"," 'Loss/localization_loss': 0.04303089,\n"," 'Loss/regularization_loss': 2.5136697,\n"," 'Loss/total_loss': 2.7260902,\n"," 'learning_rate': 0.0020241188}\n","I0420 22:28:08.541310 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.16938958,\n"," 'Loss/localization_loss': 0.04303089,\n"," 'Loss/regularization_loss': 2.5136697,\n"," 'Loss/total_loss': 2.7260902,\n"," 'learning_rate': 0.0020241188}\n","INFO:tensorflow:Step 8800 per-step time 0.959s\n","I0420 22:29:44.402734 139650086602624 model_lib_v2.py:707] Step 8800 per-step time 0.959s\n","INFO:tensorflow:{'Loss/classification_loss': 0.12419332,\n"," 'Loss/localization_loss': 0.0341034,\n"," 'Loss/regularization_loss': 2.5098586,\n"," 'Loss/total_loss': 2.6681554,\n"," 'learning_rate': 0.0017290902}\n","I0420 22:29:44.402998 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.12419332,\n"," 'Loss/localization_loss': 0.0341034,\n"," 'Loss/regularization_loss': 2.5098586,\n"," 'Loss/total_loss': 2.6681554,\n"," 'learning_rate': 0.0017290902}\n","INFO:tensorflow:Step 8900 per-step time 0.958s\n","I0420 22:31:20.238395 139650086602624 model_lib_v2.py:707] Step 8900 per-step time 0.958s\n","INFO:tensorflow:{'Loss/classification_loss': 0.20273057,\n"," 'Loss/localization_loss': 0.065489344,\n"," 'Loss/regularization_loss': 2.506622,\n"," 'Loss/total_loss': 2.774842,\n"," 'learning_rate': 0.0014563214}\n","I0420 22:31:20.238717 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.20273057,\n"," 'Loss/localization_loss': 0.065489344,\n"," 'Loss/regularization_loss': 2.506622,\n"," 'Loss/total_loss': 2.774842,\n"," 'learning_rate': 0.0014563214}\n","INFO:tensorflow:Step 9000 per-step time 0.958s\n","I0420 22:32:56.079465 139650086602624 model_lib_v2.py:707] Step 9000 per-step time 0.958s\n","INFO:tensorflow:{'Loss/classification_loss': 0.1211775,\n"," 'Loss/localization_loss': 0.027593859,\n"," 'Loss/regularization_loss': 2.5039172,\n"," 'Loss/total_loss': 2.6526885,\n"," 'learning_rate': 0.0012061464}\n","I0420 22:32:56.079741 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.1211775,\n"," 'Loss/localization_loss': 0.027593859,\n"," 'Loss/regularization_loss': 2.5039172,\n"," 'Loss/total_loss': 2.6526885,\n"," 'learning_rate': 0.0012061464}\n","INFO:tensorflow:Step 9100 per-step time 0.973s\n","I0420 22:34:33.392375 139650086602624 model_lib_v2.py:707] Step 9100 per-step time 0.973s\n","INFO:tensorflow:{'Loss/classification_loss': 0.14009845,\n"," 'Loss/localization_loss': 0.031053562,\n"," 'Loss/regularization_loss': 2.5016952,\n"," 'Loss/total_loss': 2.6728473,\n"," 'learning_rate': 0.0009788703}\n","I0420 22:34:33.392656 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.14009845,\n"," 'Loss/localization_loss': 0.031053562,\n"," 'Loss/regularization_loss': 2.5016952,\n"," 'Loss/total_loss': 2.6728473,\n"," 'learning_rate': 0.0009788703}\n","INFO:tensorflow:Step 9200 per-step time 0.959s\n","I0420 22:36:09.291288 139650086602624 model_lib_v2.py:707] Step 9200 per-step time 0.959s\n","INFO:tensorflow:{'Loss/classification_loss': 0.11613784,\n"," 'Loss/localization_loss': 0.02258787,\n"," 'Loss/regularization_loss': 2.4999106,\n"," 'Loss/total_loss': 2.6386364,\n"," 'learning_rate': 0.0007747662}\n","I0420 22:36:09.291585 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.11613784,\n"," 'Loss/localization_loss': 0.02258787,\n"," 'Loss/regularization_loss': 2.4999106,\n"," 'Loss/total_loss': 2.6386364,\n"," 'learning_rate': 0.0007747662}\n","INFO:tensorflow:Step 9300 per-step time 0.959s\n","I0420 22:37:45.220881 139650086602624 model_lib_v2.py:707] Step 9300 per-step time 0.959s\n","INFO:tensorflow:{'Loss/classification_loss': 0.1414753,\n"," 'Loss/localization_loss': 0.030988932,\n"," 'Loss/regularization_loss': 2.4985132,\n"," 'Loss/total_loss': 2.6709774,\n"," 'learning_rate': 0.00059408427}\n","I0420 22:37:45.221140 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.1414753,\n"," 'Loss/localization_loss': 0.030988932,\n"," 'Loss/regularization_loss': 2.4985132,\n"," 'Loss/total_loss': 2.6709774,\n"," 'learning_rate': 0.00059408427}\n","INFO:tensorflow:Step 9400 per-step time 0.960s\n","I0420 22:39:21.187588 139650086602624 model_lib_v2.py:707] Step 9400 per-step time 0.960s\n","INFO:tensorflow:{'Loss/classification_loss': 0.1931212,\n"," 'Loss/localization_loss': 0.03540194,\n"," 'Loss/regularization_loss': 2.4974568,\n"," 'Loss/total_loss': 2.7259798,\n"," 'learning_rate': 0.00043704748}\n","I0420 22:39:21.187855 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.1931212,\n"," 'Loss/localization_loss': 0.03540194,\n"," 'Loss/regularization_loss': 2.4974568,\n"," 'Loss/total_loss': 2.7259798,\n"," 'learning_rate': 0.00043704748}\n","INFO:tensorflow:Step 9500 per-step time 0.959s\n","I0420 22:40:57.055347 139650086602624 model_lib_v2.py:707] Step 9500 per-step time 0.959s\n","INFO:tensorflow:{'Loss/classification_loss': 0.17282745,\n"," 'Loss/localization_loss': 0.048202608,\n"," 'Loss/regularization_loss': 2.4966943,\n"," 'Loss/total_loss': 2.7177243,\n"," 'learning_rate': 0.0003038442}\n","I0420 22:40:57.055718 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.17282745,\n"," 'Loss/localization_loss': 0.048202608,\n"," 'Loss/regularization_loss': 2.4966943,\n"," 'Loss/total_loss': 2.7177243,\n"," 'learning_rate': 0.0003038442}\n","INFO:tensorflow:Step 9600 per-step time 0.960s\n","I0420 22:42:33.070377 139650086602624 model_lib_v2.py:707] Step 9600 per-step time 0.960s\n","INFO:tensorflow:{'Loss/classification_loss': 0.19775455,\n"," 'Loss/localization_loss': 0.041801706,\n"," 'Loss/regularization_loss': 2.496179,\n"," 'Loss/total_loss': 2.7357354,\n"," 'learning_rate': 0.00019463777}\n","I0420 22:42:33.070660 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.19775455,\n"," 'Loss/localization_loss': 0.041801706,\n"," 'Loss/regularization_loss': 2.496179,\n"," 'Loss/total_loss': 2.7357354,\n"," 'learning_rate': 0.00019463777}\n","INFO:tensorflow:Step 9700 per-step time 0.958s\n","I0420 22:44:08.864306 139650086602624 model_lib_v2.py:707] Step 9700 per-step time 0.958s\n","INFO:tensorflow:{'Loss/classification_loss': 0.14153165,\n"," 'Loss/localization_loss': 0.05668019,\n"," 'Loss/regularization_loss': 2.4958606,\n"," 'Loss/total_loss': 2.6940725,\n"," 'learning_rate': 0.00010956168}\n","I0420 22:44:08.864617 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.14153165,\n"," 'Loss/localization_loss': 0.05668019,\n"," 'Loss/regularization_loss': 2.4958606,\n"," 'Loss/total_loss': 2.6940725,\n"," 'learning_rate': 0.00010956168}\n","INFO:tensorflow:Step 9800 per-step time 0.958s\n","I0420 22:45:44.685405 139650086602624 model_lib_v2.py:707] Step 9800 per-step time 0.958s\n","INFO:tensorflow:{'Loss/classification_loss': 0.120113544,\n"," 'Loss/localization_loss': 0.023466123,\n"," 'Loss/regularization_loss': 2.495694,\n"," 'Loss/total_loss': 2.6392736,\n"," 'learning_rate': 4.871845e-05}\n","I0420 22:45:44.685677 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.120113544,\n"," 'Loss/localization_loss': 0.023466123,\n"," 'Loss/regularization_loss': 2.495694,\n"," 'Loss/total_loss': 2.6392736,\n"," 'learning_rate': 4.871845e-05}\n","INFO:tensorflow:Step 9900 per-step time 0.959s\n","I0420 22:47:20.602963 139650086602624 model_lib_v2.py:707] Step 9900 per-step time 0.959s\n","INFO:tensorflow:{'Loss/classification_loss': 0.11487887,\n"," 'Loss/localization_loss': 0.021483408,\n"," 'Loss/regularization_loss': 2.4956286,\n"," 'Loss/total_loss': 2.631991,\n"," 'learning_rate': 1.2183189e-05}\n","I0420 22:47:20.603272 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.11487887,\n"," 'Loss/localization_loss': 0.021483408,\n"," 'Loss/regularization_loss': 2.4956286,\n"," 'Loss/total_loss': 2.631991,\n"," 'learning_rate': 1.2183189e-05}\n","INFO:tensorflow:Step 10000 per-step time 0.959s\n","I0420 22:48:56.521745 139650086602624 model_lib_v2.py:707] Step 10000 per-step time 0.959s\n","INFO:tensorflow:{'Loss/classification_loss': 0.14624088,\n"," 'Loss/localization_loss': 0.037704933,\n"," 'Loss/regularization_loss': 2.4956214,\n"," 'Loss/total_loss': 2.6795673,\n"," 'learning_rate': 0.0}\n","I0420 22:48:56.522028 139650086602624 model_lib_v2.py:708] {'Loss/classification_loss': 0.14624088,\n"," 'Loss/localization_loss': 0.037704933,\n"," 'Loss/regularization_loss': 2.4956214,\n"," 'Loss/total_loss': 2.6795673,\n"," 'learning_rate': 0.0}\n"]}]},{"cell_type":"code","source":["# from tensorflow.python.client import device_lib\n","# device_lib.list_local_devices()"],"metadata":{"id":"Lwhjc4TCkCXO","executionInfo":{"status":"ok","timestamp":1650494984448,"user_tz":240,"elapsed":194,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cUlQnyICce6w","executionInfo":{"status":"ok","timestamp":1650494986086,"user_tz":240,"elapsed":185,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"d8874142-8fe6-476d-8231-9e44815b6657"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Apr 20 22:49:45 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   56C    P0    30W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"7B9kJ5khk-tt","executionInfo":{"status":"ok","timestamp":1650494993525,"user_tz":240,"elapsed":211,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"b307d1d7-4b92-49bd-e98b-f1926888d369"},"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/training'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["# # Copy models to drive before exporting.\n","\n","# !cp -r models/ /content/drive/MyDrive/dc/AI-ENTERPRISE/new_models"],"metadata":{"id":"-Ys8hyRik5Hu","executionInfo":{"status":"ok","timestamp":1650495005436,"user_tz":240,"elapsed":167,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","metadata":{"id":"UeI2URnR9zhw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650495080201,"user_tz":240,"elapsed":73619,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"0c122d6c-fba2-47ab-89c7-94d5ef8e2c58"},"source":["!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path /content/training/models/my-pretrained-model/pipeline.config --trained_checkpoint_dir /content/training/models/my-pretrained-model --output_directory /content/training/exported_models/my_model"],"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-04-20 22:50:10.460398: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n","Instructions for updating:\n","back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n","Instead of:\n","results = tf.map_fn(fn, elems, back_prop=False)\n","Use:\n","results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n","W0420 22:50:10.598455 139804420654976 deprecation.py:615] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n","Instructions for updating:\n","back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n","Instead of:\n","results = tf.map_fn(fn, elems, back_prop=False)\n","Use:\n","results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n","2022-04-20 22:50:31.196165: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f25b6771e50>, because it is not built.\n","W0420 22:50:35.450044 139804420654976 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f25b6771e50>, because it is not built.\n","W0420 22:51:06.976896 139804420654976 save.py:265] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 208). These functions will not be directly callable after loading.\n","INFO:tensorflow:Assets written to: /content/training/exported_models/my_model/saved_model/assets\n","I0420 22:51:16.551149 139804420654976 builder_impl.py:780] Assets written to: /content/training/exported_models/my_model/saved_model/assets\n","INFO:tensorflow:Writing pipeline config file to /content/training/exported_models/my_model/pipeline.config\n","I0420 22:51:17.525099 139804420654976 config_util.py:254] Writing pipeline config file to /content/training/exported_models/my_model/pipeline.config\n"]}]},{"cell_type":"code","source":["# Copy models to drive before exporting.\n","\n","!cp -r exported_models/ /content/drive/MyDrive/DurhamCollege/AIDI/term2/PROJECT-SHARED/AI-ENTERPRISE/latest"],"metadata":{"id":"EmoLmnb-CEU-","executionInfo":{"status":"ok","timestamp":1650495107311,"user_tz":240,"elapsed":1399,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}}},"execution_count":62,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GIIKwpxtGAhK"},"source":["### **Inferencing My Trained Models**"]},{"cell_type":"code","source":["# !rm -rf /content/training/exported_models"],"metadata":{"id":"rWdO5WvxHZrd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !cp -r /content/drive/MyDrive/DurhamCollege/AIDI/term2/PROJECT-SHARED/AI-ENTERPRISE/exported_models /content/training"],"metadata":{"id":"xuZDCRclHMnf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Object Detection (On Image) From TF2 Saved Model\n","=====================================\n","\"\"\"\n","\n","import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n","import pathlib\n","import tensorflow as tf\n","import cv2\n","import argparse\n","from google.colab.patches import cv2_imshow\n","\n","# Enable GPU dynamic memory allocation\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","for gpu in gpus:\n","    tf.config.experimental.set_memory_growth(gpu, True)\n","\n","# PROVIDE PATH TO IMAGE DIRECTORY\n","IMAGE_PATHS = \"/content/drive/MyDrive/dc/AI-ENTERPRISE/pascal_xml_annotation/train/sample_006.png\"\n","\n","# PROVIDE PATH TO MODEL DIRECTORY\n","PATH_TO_MODEL_DIR = '/content/training/exported_models/my_model'\n","\n","# PROVIDE PATH TO LABEL MAP\n","PATH_TO_LABELS = '/content/training/annotations/label_map.pbtxt'\n","\n","# PROVIDE THE MINIMUM CONFIDENCE THRESHOLD\n","MIN_CONF_THRESH = float(0.60)"],"metadata":{"id":"vZDpCHvLD9nP","executionInfo":{"status":"ok","timestamp":1650495420708,"user_tz":240,"elapsed":195,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["# # LOAD THE MODEL\n","\n","# import time\n","# from object_detection.utils import label_map_util\n","# from object_detection.utils import visualization_utils as viz_utils\n","\n","# PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n","\n","# print('Loading model...', end='')\n","# start_time = time.time()\n","\n","# # LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n","# detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n","\n","# end_time = time.time()\n","# elapsed_time = end_time - start_time\n","# print('Done! Took {} seconds'.format(elapsed_time))\n","\n","# # LOAD LABEL MAP DATA FOR PLOTTING\n","\n","# category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kYMtAvnNDYJ2","executionInfo":{"status":"ok","timestamp":1650495257742,"user_tz":240,"elapsed":19327,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"ee101874-2e85-419a-801f-6f1b6bf7c536"},"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading model...Done! Took 19.166515827178955 seconds\n"]}]},{"cell_type":"code","metadata":{"id":"spZJ4ms3FqRT","colab":{"base_uri":"https://localhost:8080/","height":254},"executionInfo":{"status":"error","timestamp":1650495453412,"user_tz":240,"elapsed":176,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"cd83cc94-6e9c-4c1e-da0e-b10d921ddaf5"},"source":["import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n","\n","def load_image_into_numpy_array(path):\n","    \"\"\"Load an image from file into a numpy array.\n","    Puts image into numpy array to feed into tensorflow graph.\n","    Note that by convention we put it into a numpy array with shape\n","    (height, width, channels), where channels=3 for RGB.\n","    Args:\n","      path: the file path to the image\n","    Returns:\n","      uint8 numpy array with shape (img_height, img_width, 3)\n","    \"\"\"\n","    return np.array(Image.open(path))\n","\n","print('Running inference for {}... '.format(IMAGE_PATHS), end='')\n","\n","image = cv2.imread(IMAGE_PATHS)\n","image_rgb = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","image_expanded = np.expand_dims(image_rgb, axis=0)\n","\n","# The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n","input_tensor = tf.convert_to_tensor(image)\n","# The model expects a batch of images, so add an axis with `tf.newaxis`.\n","input_tensor = input_tensor[tf.newaxis, ...]\n","\n","# input_tensor = np.expand_dims(image_np, 0)\n","detections = detect_fn(input_tensor)\n","\n","# All outputs are batches tensors.\n","# Convert to numpy arrays, and take index [0] to remove the batch dimension.\n","# We're only interested in the first num_detections.\n","num_detections = int(detections.pop('num_detections'))\n","detections = {key: value[0, :num_detections].numpy()\n","               for key, value in detections.items()}\n","detections['num_detections'] = num_detections\n","\n","# detection_classes should be ints.\n","detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","image_with_detections = image.copy()\n","\n","# SET MIN_SCORE_THRESH BASED ON YOU MINIMUM THRESHOLD FOR DETECTIONS\n","viz_utils.visualize_boxes_and_labels_on_image_array(\n","      image_with_detections,\n","      detections['detection_boxes'],\n","      detections['detection_classes'],\n","      detections['detection_scores'],\n","      category_index,\n","      use_normalized_coordinates=True,\n","      max_boxes_to_draw=200,\n","      min_score_thresh=0.1,\n","      agnostic_mode=False)\n","\n","print('Done')\n","# DISPLAYS OUTPUT IMAGE\n","cv2_imshow(image_with_detections)\n","# CLOSES WINDOW ONCE KEY IS PRESSED\n"],"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["Running inference for /content/drive/MyDrive/dc/AI-ENTERPRISE/pascal_xml_annotation/train/sample_006.png... "]},{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-71-6ea3e0ac400a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGE_PATHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mimage_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2BGR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mimage_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_rgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"]}]},{"cell_type":"markdown","source":["### Custom pred 2"],"metadata":{"id":"3iXcSNwLFMTc"}},{"cell_type":"code","source":["from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","import io\n","import base64"],"metadata":{"id":"PdQKvtIQF2vL","executionInfo":{"status":"ok","timestamp":1650495552917,"user_tz":240,"elapsed":248,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}}},"execution_count":72,"outputs":[]},{"cell_type":"code","source":["# minimum required score for prediction\n","MIN_THRESH = 0.1\n","\n","# max num of boxes/prediction to draw on the image\n","MAX_BOXES = 1\n","\n","# load the label map\n","category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n","\n","label = []"],"metadata":{"id":"lRlPMnPyFxkC","executionInfo":{"status":"ok","timestamp":1650495553141,"user_tz":240,"elapsed":5,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}}},"execution_count":73,"outputs":[]},{"cell_type":"code","source":["location = f\"{TRAIN_IMAGES_DRIVE_PATH}/sample_013.png\"\n","\n","#read the image using opencv\n","image = cv2.imread(location)\n","image =cv2.cvtColor(image, cv2.COLOR_RGB2BGR)"],"metadata":{"id":"PyvL1FPpFXhq","executionInfo":{"status":"ok","timestamp":1650495559000,"user_tz":240,"elapsed":5608,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","metadata":{"id":"k0KheEfPGYhO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650495563611,"user_tz":240,"elapsed":4623,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}},"outputId":"85fcbbc6-41fc-4feb-f771-d398da7ebe69"},"source":["# make predictions on the image\n","# The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n","input_tensor = tf.convert_to_tensor(image)\n","# The model expects a batch of images, so add an axis with `tf.newaxis`.\n","input_tensor = input_tensor[tf.newaxis, ...]\n","\n","# input_tensor = np.expand_dims(image_np, 0)\n","detections = detect_fn(input_tensor)\n","\n","# All outputs are batches tensors.\n","# Convert to numpy arrays, and take index [0] to remove the batch dimension.\n","# We're only interested in the first num_detections.\n","num_detections = int(detections.pop('num_detections'))\n","detections = {key: value[0, :num_detections].numpy()\n","            for key, value in detections.items()}\n","\n","detections['num_detections'] = num_detections\n","\n","# detection_classes should be ints.\n","detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","for i in range(len(detections['detection_scores'])):\n","  if(detections['detection_scores'][i] >= MIN_THRESH):\n","      output = (category_index.get(detections['detection_classes'][i]).get('name'),detections['detection_scores'][i]*100)\n","      label.append(output)\n","\n","image_detections = image.copy()\n","\n","\n","viz_utils.visualize_boxes_and_labels_on_image_array(\n","image_detections,\n","detections['detection_boxes'],\n","detections['detection_classes'],\n","detections['detection_scores'],\n","category_index,\n","use_normalized_coordinates = True,\n","max_boxes_to_draw = MAX_BOXES,\n","min_score_thresh = MIN_THRESH,\n","agnostic_mode = False)\n","\n","img = Image.fromarray(image_detections.astype(\"uint8\"))\n","rawBytes = io.BytesIO()\n","img.save(rawBytes, \"JPEG\")\n","encodedImg = base64.b64encode(rawBytes.getvalue())\n","\n","#sort based on 2nd element(score)\n","label.sort(key = lambda x: x[1])\n","data = {'location': str(encodedImg), 'predict': label}\n","data"],"execution_count":75,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'location': \"b'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'\",\n"," 'predict': [('speedLimit35', 10.400320589542389),\n","  ('keepRight', 11.227446049451828),\n","  ('yield', 12.59007602930069),\n","  ('yield', 12.641946971416473),\n","  ('keepRight', 13.414067029953003),\n","  ('keepRight', 13.476118445396423),\n","  ('keepRight', 15.038049221038818),\n","  ('stop', 15.373177826404572),\n","  ('stop', 30.415093898773193)]}"]},"metadata":{},"execution_count":75}]},{"cell_type":"code","source":["import time\n","time.sleep(500)"],"metadata":{"id":"9o4nhfR6FodP","executionInfo":{"status":"ok","timestamp":1650498366717,"user_tz":240,"elapsed":500439,"user":{"displayName":"Ram Raghu Sankar","userId":"14421585886042400768"}}},"execution_count":78,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"DMwAtLN0TtFu"},"execution_count":null,"outputs":[]}]}